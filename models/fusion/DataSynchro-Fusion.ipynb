{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbee1a3-895d-4e48-b9ef-a88e055b2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20984/650330371.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 1\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([2.7200], dtype=torch.float64)\n",
      "Batch 1\n",
      "Video Features (first 3 rows):\n",
      "[[[ 9.2403534e-05 -6.9705996e-04  7.8170612e-02 ...  3.2085361e-05\n",
      "   -6.8727362e-01 -5.8516918e-04]\n",
      "  [ 9.6840100e-05 -7.8241242e-04  2.5183462e-02 ...  6.2751940e-05\n",
      "   -8.3312464e-01 -7.5931585e-04]\n",
      "  [ 9.1237474e-05 -8.1487821e-04  1.0307739e-02 ...  7.0110924e-05\n",
      "   -7.6311010e-01 -7.3544384e-04]\n",
      "  [ 9.1237474e-05 -8.1487821e-04  1.0307739e-02 ...  7.0110924e-05\n",
      "   -7.6311010e-01 -7.3544384e-04]\n",
      "  [ 9.1237474e-05 -8.1487821e-04  1.0307739e-02 ...  7.0110924e-05\n",
      "   -7.6311010e-01 -7.3544384e-04]\n",
      "  [ 9.1237474e-05 -8.1487821e-04  1.0307739e-02 ...  7.0110924e-05\n",
      "   -7.6311010e-01 -7.3544384e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.0765605   0.01174777  0.03130768 ...  0.0145654  -0.00822521\n",
      "   -0.08022697]\n",
      "  [-0.00922577  0.00220311 -0.03276379 ... -0.10539339 -0.01948776\n",
      "   -0.05450479]]]\n",
      "Labels:\n",
      "[[0.3954582 0.414567 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 2\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([3.7400], dtype=torch.float64)\n",
      "Batch 2\n",
      "Video Features (first 3 rows):\n",
      "[[[ 9.2403534e-05 -6.9705996e-04  7.8170612e-02 ...  3.2085361e-05\n",
      "   -6.8727362e-01 -5.8516918e-04]\n",
      "  [ 9.6840100e-05 -7.8241242e-04  2.5183462e-02 ...  6.2751940e-05\n",
      "   -8.3312464e-01 -7.5931585e-04]\n",
      "  [ 9.1237474e-05 -8.1487821e-04  1.0307739e-02 ...  7.0110924e-05\n",
      "   -7.6311010e-01 -7.3544384e-04]\n",
      "  [ 9.6559175e-05 -8.5253385e-04 -1.1648138e-02 ...  5.8458783e-05\n",
      "   -8.7619311e-01 -6.5714563e-04]\n",
      "  [ 9.8871111e-05 -6.6062575e-04  1.5578832e-01 ...  5.2636475e-05\n",
      "   -8.6046362e-01 -5.9386925e-04]\n",
      "  [ 1.0019006e-04 -5.7587354e-04  2.4506587e-01 ...  3.6966827e-05\n",
      "   -8.2392323e-01 -6.2386942e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.00922577  0.00220311 -0.03276379 ... -0.10539339 -0.01948776\n",
      "   -0.05450479]\n",
      "  [-0.03726481 -0.00794975  0.08963108 ... -0.24067189 -0.01556701\n",
      "   -0.03621585]]]\n",
      "Labels:\n",
      "[[0.403589  0.3261646]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 3\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([4.7600], dtype=torch.float64)\n",
      "Batch 3\n",
      "Video Features (first 3 rows):\n",
      "[[[ 9.65591753e-05 -8.52533849e-04 -1.16481381e-02 ...  5.84587833e-05\n",
      "   -8.76193106e-01 -6.57145632e-04]\n",
      "  [ 9.88711108e-05 -6.60625752e-04  1.55788317e-01 ...  5.26364747e-05\n",
      "   -8.60463619e-01 -5.93869248e-04]\n",
      "  [ 1.00190060e-04 -5.75873535e-04  2.45065868e-01 ...  3.69668269e-05\n",
      "   -8.23923230e-01 -6.23869419e-04]\n",
      "  [ 8.89483053e-05 -1.13962358e-03 -5.91416843e-02 ...  7.94981315e-05\n",
      "   -8.26056361e-01 -6.96287141e-04]\n",
      "  [ 8.14131854e-05 -1.09042518e-03 -1.56372368e-01 ...  8.64242174e-05\n",
      "   -7.62870789e-01 -6.88872882e-04]\n",
      "  [ 7.86088640e-05 -1.20135897e-03 -2.21942782e-01 ...  1.04359126e-04\n",
      "   -6.32003784e-01 -7.38896779e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.03726481 -0.00794975  0.08963108 ... -0.24067189 -0.01556701\n",
      "   -0.03621585]\n",
      "  [-0.01966598  0.02424243 -0.02048002 ... -0.06975229  0.00680508\n",
      "   -0.00960357]]]\n",
      "Labels:\n",
      "[[0.299693  0.2437658]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 4\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([5.7800], dtype=torch.float64)\n",
      "Batch 4\n",
      "Video Features (first 3 rows):\n",
      "[[[ 8.89483053e-05 -1.13962358e-03 -5.91416843e-02 ...  7.94981315e-05\n",
      "   -8.26056361e-01 -6.96287141e-04]\n",
      "  [ 8.14131854e-05 -1.09042518e-03 -1.56372368e-01 ...  8.64242174e-05\n",
      "   -7.62870789e-01 -6.88872882e-04]\n",
      "  [ 7.86088640e-05 -1.20135897e-03 -2.21942782e-01 ...  1.04359126e-04\n",
      "   -6.32003784e-01 -7.38896779e-04]\n",
      "  [ 7.47032173e-05 -1.13531470e-03 -1.07373975e-01 ...  1.07565524e-04\n",
      "   -7.61988878e-01 -6.59845711e-04]\n",
      "  [ 7.21709657e-05 -1.08717429e-03 -1.27447128e-01 ...  1.04172410e-04\n",
      "   -7.50457942e-01 -6.31719478e-04]\n",
      "  [ 7.78377653e-05 -9.76500334e-04  1.15288846e-01 ...  1.06971303e-04\n",
      "   -7.87405789e-01 -7.00525998e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.01966598  0.02424243 -0.02048002 ... -0.06975229  0.00680508\n",
      "   -0.00960357]\n",
      "  [-0.04264369  0.02220513 -0.06293589 ... -0.03741995  0.02016286\n",
      "   -0.00847431]]]\n",
      "Labels:\n",
      "[[0.246725  0.0822614]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 5\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([6.8000], dtype=torch.float64)\n",
      "Batch 5\n",
      "Video Features (first 3 rows):\n",
      "[[[ 7.47032173e-05 -1.13531470e-03 -1.07373975e-01 ...  1.07565524e-04\n",
      "   -7.61988878e-01 -6.59845711e-04]\n",
      "  [ 7.21709657e-05 -1.08717429e-03 -1.27447128e-01 ...  1.04172410e-04\n",
      "   -7.50457942e-01 -6.31719478e-04]\n",
      "  [ 7.78377653e-05 -9.76500334e-04  1.15288846e-01 ...  1.06971303e-04\n",
      "   -7.87405789e-01 -7.00525998e-04]\n",
      "  [ 8.12607905e-05 -1.12568191e-03  1.58531815e-01 ...  8.15373351e-05\n",
      "   -7.26363659e-01 -7.51178421e-04]\n",
      "  [ 7.51845582e-05 -1.07350911e-03  1.64554700e-01 ...  8.04408046e-05\n",
      "   -6.66462660e-01 -7.34463509e-04]\n",
      "  [ 7.58614406e-05 -1.08970969e-03  1.01473659e-01 ...  8.49144853e-05\n",
      "   -7.07862616e-01 -7.32698012e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.04264369  0.02220513 -0.06293589 ... -0.03741995  0.02016286\n",
      "   -0.00847431]\n",
      "  [-0.01372351 -0.01086067  0.13585807 ... -0.17202117  0.00581831\n",
      "   -0.1184046 ]]]\n",
      "Labels:\n",
      "[[0.18147  0.104104]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 6\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([7.8200], dtype=torch.float64)\n",
      "Batch 6\n",
      "Video Features (first 3 rows):\n",
      "[[[ 8.1260790e-05 -1.1256819e-03  1.5853181e-01 ...  8.1537335e-05\n",
      "   -7.2636366e-01 -7.5117842e-04]\n",
      "  [ 7.5184558e-05 -1.0735091e-03  1.6455470e-01 ...  8.0440805e-05\n",
      "   -6.6646266e-01 -7.3446351e-04]\n",
      "  [ 7.5861441e-05 -1.0897097e-03  1.0147366e-01 ...  8.4914485e-05\n",
      "   -7.0786262e-01 -7.3269801e-04]\n",
      "  [ 7.3313131e-05 -1.2216392e-03 -1.7290528e-01 ...  9.6238102e-05\n",
      "   -5.9866500e-01 -7.5114309e-04]\n",
      "  [ 8.3850020e-05 -1.4144904e-03 -2.4557963e-01 ...  8.2170292e-05\n",
      "   -6.5846348e-01 -9.5256878e-04]\n",
      "  [ 8.4941355e-05 -1.1595603e-03 -2.1292105e-01 ...  1.0605089e-04\n",
      "   -8.1836039e-01 -8.8259252e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.01372351 -0.01086067  0.13585807 ... -0.17202117  0.00581831\n",
      "   -0.1184046 ]\n",
      "  [-0.1388016   0.02969924  0.08063597 ...  0.03817603  0.00868024\n",
      "   -0.05278179]]]\n",
      "Labels:\n",
      "[[0.2512062 0.0991596]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 7\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([8.8400], dtype=torch.float64)\n",
      "Batch 7\n",
      "Video Features (first 3 rows):\n",
      "[[[ 7.3313131e-05 -1.2216392e-03 -1.7290528e-01 ...  9.6238102e-05\n",
      "   -5.9866500e-01 -7.5114309e-04]\n",
      "  [ 8.3850020e-05 -1.4144904e-03 -2.4557963e-01 ...  8.2170292e-05\n",
      "   -6.5846348e-01 -9.5256878e-04]\n",
      "  [ 8.4941355e-05 -1.1595603e-03 -2.1292105e-01 ...  1.0605089e-04\n",
      "   -8.1836039e-01 -8.8259252e-04]\n",
      "  [ 7.7337601e-05 -1.0492660e-03 -2.3648921e-01 ...  8.4481384e-05\n",
      "   -3.6263373e-01 -7.1345904e-04]\n",
      "  [ 8.0351398e-05 -1.0803334e-03 -2.3852536e-01 ...  9.7368480e-05\n",
      "   -6.0209954e-01 -7.4275024e-04]\n",
      "  [ 8.3203173e-05 -1.3622157e-03 -3.0442512e-01 ...  9.1401766e-05\n",
      "   -6.3749784e-01 -9.0527878e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.1388016   0.02969924  0.08063597 ...  0.03817603  0.00868024\n",
      "   -0.05278179]\n",
      "  [-0.0232813   0.00045109  0.03732146 ... -0.13941287 -0.00725406\n",
      "   -0.015546  ]]]\n",
      "Labels:\n",
      "[[0.259703  0.2474948]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 8\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([9.8600], dtype=torch.float64)\n",
      "Batch 8\n",
      "Video Features (first 3 rows):\n",
      "[[[ 7.7337601e-05 -1.0492660e-03 -2.3648921e-01 ...  8.4481384e-05\n",
      "   -3.6263373e-01 -7.1345904e-04]\n",
      "  [ 8.0351398e-05 -1.0803334e-03 -2.3852536e-01 ...  9.7368480e-05\n",
      "   -6.0209954e-01 -7.4275024e-04]\n",
      "  [ 8.3203173e-05 -1.3622157e-03 -3.0442512e-01 ...  9.1401766e-05\n",
      "   -6.3749784e-01 -9.0527878e-04]\n",
      "  [ 8.6199616e-05 -1.2425616e-03 -1.8824457e-01 ...  7.3318122e-05\n",
      "   -7.7950013e-01 -7.7186915e-04]\n",
      "  [ 8.5233827e-05 -8.1192161e-04  2.4765108e-02 ...  8.3073843e-05\n",
      "   -8.3033907e-01 -5.6326290e-04]\n",
      "  [ 8.5102474e-05 -9.6167799e-04 -2.4214428e-02 ...  5.2759915e-05\n",
      "   -7.5386065e-01 -5.8503961e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.0232813   0.00045109  0.03732146 ... -0.13941287 -0.00725406\n",
      "   -0.015546  ]\n",
      "  [-0.00284262  0.00351296  0.0504139  ... -0.17010124  0.02069935\n",
      "   -0.08214796]]]\n",
      "Labels:\n",
      "[[0.2632484 0.3342392]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 9\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([10.8800], dtype=torch.float64)\n",
      "Batch 9\n",
      "Video Features (first 3 rows):\n",
      "[[[ 8.61996159e-05 -1.24256162e-03 -1.88244566e-01 ...  7.33181223e-05\n",
      "   -7.79500127e-01 -7.71869149e-04]\n",
      "  [ 8.52338271e-05 -8.11921607e-04  2.47651078e-02 ...  8.30738427e-05\n",
      "   -8.30339074e-01 -5.63262904e-04]\n",
      "  [ 8.51024743e-05 -9.61677986e-04 -2.42144279e-02 ...  5.27599150e-05\n",
      "   -7.53860652e-01 -5.85039612e-04]\n",
      "  [ 8.34186576e-05 -6.03890978e-04 -7.59128779e-02 ...  7.77917739e-05\n",
      "   -6.79967642e-01 -5.97955368e-04]\n",
      "  [ 7.89403857e-05 -1.20006804e-03 -1.03183225e-01 ...  6.97159194e-05\n",
      "   -4.73735839e-01 -7.02159537e-04]\n",
      "  [ 8.64528774e-05 -1.20492396e-03 -2.88531687e-02 ...  5.96145401e-05\n",
      "   -4.69510883e-01 -7.21053337e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.00284262  0.00351296  0.0504139  ... -0.17010124  0.02069935\n",
      "   -0.08214796]\n",
      "  [-0.01529734  0.00585448 -0.13155396 ... -0.00583397  0.01399152\n",
      "   -0.01415438]]]\n",
      "Labels:\n",
      "[[0.4850514 0.5206528]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 10\n",
      "Video Name: ('SEW1101',), Timestamp: tensor([11.9000], dtype=torch.float64)\n",
      "Batch 10\n",
      "Video Features (first 3 rows):\n",
      "[[[ 8.34186576e-05 -6.03890978e-04 -7.59128779e-02 ...  7.77917739e-05\n",
      "   -6.79967642e-01 -5.97955368e-04]\n",
      "  [ 7.89403857e-05 -1.20006804e-03 -1.03183225e-01 ...  6.97159194e-05\n",
      "   -4.73735839e-01 -7.02159537e-04]\n",
      "  [ 8.64528774e-05 -1.20492396e-03 -2.88531687e-02 ...  5.96145401e-05\n",
      "   -4.69510883e-01 -7.21053337e-04]\n",
      "  [ 9.68504537e-05 -8.03104253e-04  1.60134628e-01 ...  6.60958103e-05\n",
      "   -8.59228551e-01 -7.46783742e-04]\n",
      "  [ 8.75346232e-05 -8.10513564e-04  2.88199693e-01 ...  5.76953280e-05\n",
      "   -8.27313066e-01 -5.11405931e-04]\n",
      "  [ 9.36695069e-05 -8.21707887e-04  4.29533750e-01 ...  4.00501340e-05\n",
      "   -8.49578083e-01 -5.07815625e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[-0.01529734  0.00585448 -0.13155396 ... -0.00583397  0.01399152\n",
      "   -0.01415438]\n",
      "  [-0.07476833 -0.00976293 -0.05612912 ... -0.09990717  0.01783909\n",
      "   -0.01870716]]]\n",
      "Labels:\n",
      "[[0.628358 0.638645]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (6, 256)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 768)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SynchronizedAudioVideoDataset(Dataset):\n",
    "    def __init__(self, video_df, audio_df, window_length=2, step=1): #3Frames per second, max amount frames = window_length*3\n",
    "        self.video_df = video_df\n",
    "        self.audio_df = audio_df\n",
    "        self.window_length = window_length\n",
    "        self.step = step\n",
    "        self.max_frames = window_length * 3\n",
    "        self.data = self._synchronize()\n",
    "        #step всегда пол окна, кроме случая с 1 сек, потому что аудио извлечено с шагом в секунду и нет смысла брать шаг 1.5 для шага модальностей\n",
    "\n",
    "    def _extract_video_id(self, path):\n",
    "        # This function extracts the video ID from the video file path.\n",
    "        return path.split('/')[-1].split('_')[0]\n",
    "        \n",
    "    def _synchronize(self):\n",
    "        synchronized_data = []\n",
    "        video_ids = self.video_df['path'].apply(self._extract_video_id).unique() #retrieves unique video IDs from the video dataframe's file paths.\n",
    "        \n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].apply(lambda x: self._extract_video_id(x) == video_id)]#test\n",
    "            audio_data = self.audio_df[self.audio_df['filename'].str.contains(video_id)]\n",
    "\n",
    "            start_time = 0\n",
    "            \"\"\"\n",
    "            - window of time defined by start_time and end_time (where end_time = start_time + self.window_length)\n",
    "            - video segments are selected based on their timestamps being within this window. Audio segments are chosen if their start and end timesteps fall within the window\n",
    "            - if selected video segment has less frames than self.max_frames, additional rows (copies of the last row) are appended to match self.max_frames\n",
    "            - labels for arousal and valence are taken from the last row of the windowed video data\n",
    "            \"\"\"\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)] #here smth can be wrong, check\n",
    "                #в большинстве случаев должно быть 6 фреймов в окне\n",
    "                # shape video , shape audio, timestep audio/video, labels\n",
    "                window_audio_data = audio_data[(audio_data['start_timestep'] >= start_time) & (audio_data['end_timestep'] <= end_time)] #print timesteps\n",
    "\n",
    "                if len(window_video_data) > 0 and len(window_audio_data) > 0:\n",
    "                    if len(window_video_data) < self.max_frames:\n",
    "                        additional_rows = self.max_frames - len(window_video_data)\n",
    "                        last_row = window_video_data.iloc[-1:].copy()\n",
    "                        for _ in range(additional_rows):\n",
    "                            window_video_data = pd.concat([window_video_data, last_row], ignore_index=True)\n",
    "                \n",
    "                #assert len(window_video_data)==int(self.window_length*3) вылетает ошибка сразу если не тру\n",
    "\n",
    "                    labels = window_video_data.iloc[-1][['arousal', 'valence']].values\n",
    "                    video_features = window_video_data.iloc[:, 4:].values #убрать arousal valence из фич, потому что они в лейблах\n",
    "                    audio_features = window_audio_data.iloc[:, 6:].values #выбросить пустую колонку features\n",
    "                    #распечатать все что сформировала \n",
    "                    # какие у видео и аудио начало и конец таймстеп, сколько кадров и какие лейблы, первые 10 итераций\n",
    "\n",
    "                    # Here: extract video_name and timestamp for each sample\n",
    "                    video_name = video_id\n",
    "                    timestamp = window_video_data.iloc[-1]['timestamp']\n",
    "\n",
    "                    synchronized_data.append((video_features, audio_features, labels, video_name, timestamp))\n",
    "\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "\n",
    "        return synchronized_data # contains tuples of synchronized video and audio features along with their labels, names, and timestamps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single item from the dataset by index. It ensures that video and audio features are converted to tensors of type float32 and\n",
    "        labels are processed to ensure they're in a consistent format before returning them along with the video name and timestamp.\n",
    "        \"\"\"\n",
    "        video_features, audio_features, labels, video_name, timestamp = self.data[idx]\n",
    "    \n",
    "        # Ensure labels are in a consistent format\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "        video_features_tensor = torch.tensor(video_features, dtype=torch.float32)\n",
    "        audio_features_tensor = torch.tensor(audio_features, dtype=torch.float32)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        print(f\"Video features type: {type(video_features)}, shape: {video_features.shape}\")\n",
    "        print(f\"Audio features type: {type(audio_features)}, shape: {audio_features.shape}\")\n",
    "        print(f\"Labels type: {type(labels)}, shape: {labels.shape}\")\n",
    "\n",
    "        return video_features_tensor, audio_features_tensor, labels_tensor, video_name, timestamp\n",
    "\n",
    "\n",
    "# Load video and audio data\n",
    "video_train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "video_dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "video_test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "audio_train_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_train.csv')\n",
    "audio_dev_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_dev.csv')\n",
    "audio_test_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_test.csv')\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = SynchronizedAudioVideoDataset(video_train_df, audio_train_df)\n",
    "dev_dataset = SynchronizedAudioVideoDataset(video_dev_df, audio_dev_df)\n",
    "test_dataset = SynchronizedAudioVideoDataset(video_test_df, audio_test_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 1  # For demonstration\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) #убраить шафл и проверить вручную! /changed to False..\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Assuming you have your DataLoader setup as before\n",
    "for i, (video_features, audio_features, labels, video_name, timestamp) in enumerate(train_loader):\n",
    "    if i >= 10:  # Just to limit the output to the first 10 batches\n",
    "        break\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Video Name: {video_name}, Timestamp: {timestamp}\")    \n",
    "    # Convert tensors to numpy for easy slicing and displaying\n",
    "    video_features_np = video_features.numpy()\n",
    "    audio_features_np = audio_features.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "    \n",
    "    # Print the first few rows of each. Adjust the number of rows as needed\n",
    "    num_rows_to_display = 3  # for example, to display the first 3 rows\n",
    "    \n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Video Features (first {num_rows_to_display} rows):\")\n",
    "    print(video_features_np[:num_rows_to_display])\n",
    "    \n",
    "    print(f\"Audio Features (first {num_rows_to_display} rows):\")\n",
    "    # Note: If the second dimension represents a time or sequence dimension, you may need to adjust this\n",
    "    print(audio_features_np[:, :num_rows_to_display])  # Assuming the first dimension is batch\n",
    "    \n",
    "    print(\"Labels:\")\n",
    "    print(labels_np)  # Labels might be just one per sample, depending on your data structure\n",
    "    print(\"\\n----------\\n\")\n",
    "    # why \"shape: (384, 257) \" 384 не может быть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaaa06f3-e601-439e-a638-c9d34ce5f28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 1\n",
      "Video Name: ('SEW1117',), Timestamp: tensor([115.9400], dtype=torch.float64)\n",
      "Batch 1\n",
      "Video Features (first 3 rows):\n",
      "[[[ 5.0885999e-03  8.2287894e-05 -1.3206836e-03 ...  4.3610100e-05\n",
      "   -9.7518128e-01 -5.7298515e-04]\n",
      "  [ 0.0000000e+00  8.0436737e-05 -1.3107845e-03 ...  4.6995563e-05\n",
      "   -9.6503872e-01 -6.5678888e-04]\n",
      "  [ 0.0000000e+00  7.4407202e-05 -1.1705542e-03 ...  7.4300915e-05\n",
      "   -9.2931557e-01 -7.4286928e-04]\n",
      "  ...\n",
      "  [ 0.0000000e+00  7.9427788e-05 -1.2892334e-03 ...  8.6821208e-05\n",
      "   -9.7242546e-01 -7.6293014e-04]\n",
      "  [ 0.0000000e+00  7.9427788e-05 -1.2892334e-03 ...  8.6821208e-05\n",
      "   -9.7242546e-01 -7.6293014e-04]\n",
      "  [ 0.0000000e+00  7.9427788e-05 -1.2892334e-03 ...  8.6821208e-05\n",
      "   -9.7242546e-01 -7.6293014e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.12013236  0.00393401 ... -0.011756    0.00538786\n",
      "    0.06109541]\n",
      "  [        nan -0.1366464   0.01559308 ...  0.00443726 -0.00743291\n",
      "    0.00333076]]]\n",
      "Labels:\n",
      "[[0.0310422 0.       ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 2\n",
      "Video Name: ('SEW1116',), Timestamp: tensor([127.8400], dtype=torch.float64)\n",
      "Batch 2\n",
      "Video Features (first 3 rows):\n",
      "[[[-4.4266999e-01  6.4328400e-05 -7.3555403e-04 ...  6.8841066e-05\n",
      "   -9.1923606e-01 -4.4543206e-04]\n",
      "  [-4.3408501e-01  6.7664150e-05 -7.6458527e-04 ...  6.7787536e-05\n",
      "   -9.3830150e-01 -4.2573785e-04]\n",
      "  [-4.2660800e-01  7.1307266e-05 -8.9551200e-04 ...  7.8916964e-05\n",
      "   -9.2471391e-01 -6.7125249e-04]\n",
      "  ...\n",
      "  [-4.2660800e-01  7.1307266e-05 -8.9551200e-04 ...  7.8916964e-05\n",
      "   -9.2471391e-01 -6.7125249e-04]\n",
      "  [-4.2660800e-01  7.1307266e-05 -8.9551200e-04 ...  7.8916964e-05\n",
      "   -9.2471391e-01 -6.7125249e-04]\n",
      "  [-4.2660800e-01  7.1307266e-05 -8.9551200e-04 ...  7.8916964e-05\n",
      "   -9.2471391e-01 -6.7125249e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.01392915 -0.01186464 ... -0.13766736 -0.01083063\n",
      "   -0.05340616]\n",
      "  [        nan -0.0174951  -0.01492718 ... -0.0324253   0.01411276\n",
      "    0.02684047]]]\n",
      "Labels:\n",
      "[[ 0.329461 -0.426608]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 3\n",
      "Video Name: ('SEW1205',), Timestamp: tensor([25.8400], dtype=torch.float64)\n",
      "Batch 3\n",
      "Video Features (first 3 rows):\n",
      "[[[-2.3945500e-01  6.4804211e-05 -1.0153040e-03 ...  8.3627448e-05\n",
      "   -9.5473325e-01 -4.9906923e-04]\n",
      "  [-2.3417860e-01  7.5686949e-05 -1.0340551e-03 ...  8.4307612e-05\n",
      "   -9.6474326e-01 -6.3232111e-04]\n",
      "  [-2.3407701e-01  7.8186167e-05 -9.7605784e-04 ...  6.7984845e-05\n",
      "   -9.7843736e-01 -5.7996064e-04]\n",
      "  ...\n",
      "  [-2.3407701e-01  7.3933101e-05 -1.2681438e-03 ...  7.4576717e-05\n",
      "   -9.4915211e-01 -6.8854896e-04]\n",
      "  [-2.3407701e-01  7.3933101e-05 -1.2681438e-03 ...  7.4576717e-05\n",
      "   -9.4915211e-01 -6.8854896e-04]\n",
      "  [-2.3407701e-01  7.3933101e-05 -1.2681438e-03 ...  7.4576717e-05\n",
      "   -9.4915211e-01 -6.8854896e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.01527813 -0.00888472 ... -0.07403687  0.04046349\n",
      "   -0.01409801]\n",
      "  [        nan -0.10527509  0.05808769 ... -0.02717954 -0.0033093\n",
      "   -0.17729689]]]\n",
      "Labels:\n",
      "[[-0.0805316 -0.234077 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 4\n",
      "Video Name: ('SEW1114',), Timestamp: tensor([152.6600], dtype=torch.float64)\n",
      "Batch 4\n",
      "Video Features (first 3 rows):\n",
      "[[[ 2.6885999e-02  6.8815913e-05 -7.3331280e-04 ...  7.0683964e-05\n",
      "   -7.8185380e-01 -5.7401438e-04]\n",
      "  [ 2.6885999e-02  7.0266811e-05 -7.5251015e-04 ...  6.8686837e-05\n",
      "   -7.6729995e-01 -6.1987253e-04]\n",
      "  [ 2.6885999e-02  7.6327698e-05 -6.2646461e-04 ...  7.5214288e-05\n",
      "   -9.5814365e-01 -5.8655598e-04]\n",
      "  ...\n",
      "  [ 2.6885999e-02  6.3033600e-05 -4.8561313e-04 ...  5.7837962e-05\n",
      "   -8.9181012e-01 -5.3530012e-04]\n",
      "  [ 2.6885999e-02  6.3033600e-05 -4.8561313e-04 ...  5.7837962e-05\n",
      "   -8.9181012e-01 -5.3530012e-04]\n",
      "  [ 2.6885999e-02  6.3033600e-05 -4.8561313e-04 ...  5.7837962e-05\n",
      "   -8.9181012e-01 -5.3530012e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.06273997  0.01100873 ... -0.09143581 -0.02007142\n",
      "   -0.06671694]\n",
      "  [        nan -0.03078939  0.02121414 ... -0.09155315  0.01768763\n",
      "   -0.07190622]]]\n",
      "Labels:\n",
      "[[-0.045862  0.026886]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 5\n",
      "Video Name: ('SEW1120',), Timestamp: tensor([78.8800], dtype=torch.float64)\n",
      "Batch 5\n",
      "Video Features (first 3 rows):\n",
      "[[[ 4.1356999e-02  7.5087439e-05 -1.1474963e-03 ...  7.9728357e-05\n",
      "   -8.4250194e-01 -6.7543704e-04]\n",
      "  [ 3.6508001e-02  7.1006310e-05 -1.0509575e-03 ...  8.3134939e-05\n",
      "   -8.0104810e-01 -6.5656414e-04]\n",
      "  [ 3.8908001e-02  7.7474106e-05 -1.2294928e-03 ...  4.7880578e-05\n",
      "   -8.5063338e-01 -7.1862258e-04]\n",
      "  ...\n",
      "  [ 2.7152000e-02  7.6909542e-05 -1.1998920e-03 ...  5.9304246e-05\n",
      "   -7.1249378e-01 -7.5413217e-04]\n",
      "  [ 2.7152000e-02  7.6909542e-05 -1.1998920e-03 ...  5.9304246e-05\n",
      "   -7.1249378e-01 -7.5413217e-04]\n",
      "  [ 2.7152000e-02  7.6909542e-05 -1.1998920e-03 ...  5.9304246e-05\n",
      "   -7.1249378e-01 -7.5413217e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.12997732  0.01919009 ... -0.04410991 -0.01394584\n",
      "   -0.1080595 ]\n",
      "  [        nan -0.13716273  0.00887645 ... -0.0880703  -0.01345806\n",
      "   -0.11777284]]]\n",
      "Labels:\n",
      "[[-0.0034986  0.027152 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 6\n",
      "Video Name: ('SEW1109',), Timestamp: tensor([84.6600], dtype=torch.float64)\n",
      "Batch 6\n",
      "Video Features (first 3 rows):\n",
      "[[[-8.6143002e-02  7.9657497e-05 -8.9198566e-04 ...  5.4545129e-05\n",
      "   -9.2541623e-01 -7.9357583e-04]\n",
      "  [-8.6143002e-02  8.0809092e-05 -1.0494612e-03 ...  5.6577937e-05\n",
      "   -9.0214324e-01 -9.0251619e-04]\n",
      "  [-8.0367804e-02  7.8201338e-05 -9.9398743e-04 ...  5.6318473e-05\n",
      "   -8.5928899e-01 -7.9178822e-04]\n",
      "  ...\n",
      "  [-7.9251803e-02  8.5393709e-05 -9.6309092e-04 ...  4.1082381e-05\n",
      "   -9.4649994e-01 -7.9493481e-04]\n",
      "  [-7.9251803e-02  8.5393709e-05 -9.6309092e-04 ...  4.1082381e-05\n",
      "   -9.4649994e-01 -7.9493481e-04]\n",
      "  [-7.9251803e-02  8.5393709e-05 -9.6309092e-04 ...  4.1082381e-05\n",
      "   -9.4649994e-01 -7.9493481e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan  0.00857023 -0.0149374  ...  0.04133778  0.01317919\n",
      "   -0.02679916]\n",
      "  [        nan -0.04311729  0.00033589 ... -0.12315275 -0.00325117\n",
      "   -0.05898134]]]\n",
      "Labels:\n",
      "[[-0.0031046 -0.0792518]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 7\n",
      "Video Name: ('SEW1201',), Timestamp: tensor([28.9000], dtype=torch.float64)\n",
      "Batch 7\n",
      "Video Features (first 3 rows):\n",
      "[[[ 2.1366701e-01  8.1191865e-05 -1.0707787e-03 ...  6.9830799e-05\n",
      "   -9.3763870e-01 -6.3391135e-04]\n",
      "  [ 2.0358740e-01  8.3850122e-05 -1.1043453e-03 ...  7.3314055e-05\n",
      "   -9.2989129e-01 -6.5403146e-04]\n",
      "  [ 2.0059501e-01  7.9495199e-05 -1.2088821e-03 ...  6.0649621e-05\n",
      "   -9.5832825e-01 -6.4558751e-04]\n",
      "  ...\n",
      "  [ 2.1926500e-01  7.4963333e-05 -9.8866131e-04 ...  6.9916365e-05\n",
      "   -9.6410477e-01 -6.5294927e-04]\n",
      "  [ 2.1926500e-01  7.4963333e-05 -9.8866131e-04 ...  6.9916365e-05\n",
      "   -9.6410477e-01 -6.5294927e-04]\n",
      "  [ 2.1926500e-01  7.4963333e-05 -9.8866131e-04 ...  6.9916365e-05\n",
      "   -9.6410477e-01 -6.5294927e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan  0.00139755  0.02029898 ... -0.18008426  0.03301346\n",
      "   -0.05373622]\n",
      "  [        nan -0.02033673 -0.00145438 ... -0.07424532 -0.00135067\n",
      "   -0.00191142]]]\n",
      "Labels:\n",
      "[[0.08181  0.219265]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 8\n",
      "Video Name: ('SEW2104',), Timestamp: tensor([27.8800], dtype=torch.float64)\n",
      "Batch 8\n",
      "Video Features (first 3 rows):\n",
      "[[[-1.6502000e-02  6.6258726e-05 -8.8989688e-04 ...  4.0498853e-05\n",
      "   -8.7319976e-01 -5.7940651e-04]\n",
      "  [-1.6712800e-02  6.9090769e-05 -9.8430656e-04 ...  4.9241440e-05\n",
      "   -7.8578013e-01 -6.5973512e-04]\n",
      "  [-1.6502000e-02  6.8816145e-05 -1.0302055e-03 ...  4.5387198e-05\n",
      "   -7.8123105e-01 -6.8335008e-04]\n",
      "  ...\n",
      "  [-1.6859600e-02  6.6109722e-05 -8.7445806e-04 ...  6.6831046e-05\n",
      "   -8.0815971e-01 -6.1354600e-04]\n",
      "  [-1.6859600e-02  6.6109722e-05 -8.7445806e-04 ...  6.6831046e-05\n",
      "   -8.0815971e-01 -6.1354600e-04]\n",
      "  [-1.6859600e-02  6.6109722e-05 -8.7445806e-04 ...  6.6831046e-05\n",
      "   -8.0815971e-01 -6.1354600e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan  0.00980853  0.01939376 ... -0.13836679  0.02266496\n",
      "    0.01160927]\n",
      "  [        nan -0.03587655  0.01604581 ... -0.08843789  0.03603701\n",
      "   -0.00088128]]]\n",
      "Labels:\n",
      "[[ 0.010091  -0.0168596]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 9\n",
      "Video Name: ('SEW1116',), Timestamp: tensor([28.9000], dtype=torch.float64)\n",
      "Batch 9\n",
      "Video Features (first 3 rows):\n",
      "[[[-3.2147001e-02  7.7512879e-05 -1.0536616e-03 ...  4.9945265e-05\n",
      "   -9.4966865e-01 -7.3080027e-04]\n",
      "  [-3.2147001e-02  7.5577547e-05 -1.0509482e-03 ...  3.7902348e-05\n",
      "   -9.5736670e-01 -6.7973981e-04]\n",
      "  [-3.2147001e-02  7.2258823e-05 -1.0435878e-03 ...  4.5217825e-05\n",
      "   -9.4798028e-01 -6.5848243e-04]\n",
      "  ...\n",
      "  [-3.2147001e-02  7.2377443e-05 -8.2921924e-04 ...  5.4924181e-05\n",
      "   -9.5200491e-01 -7.9228351e-04]\n",
      "  [-3.2147001e-02  7.2377443e-05 -8.2921924e-04 ...  5.4924181e-05\n",
      "   -9.5200491e-01 -7.9228351e-04]\n",
      "  [-3.2147001e-02  7.2377443e-05 -8.2921924e-04 ...  5.4924181e-05\n",
      "   -9.5200491e-01 -7.9228351e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.13514234  0.00709632 ... -0.09203181 -0.01316452\n",
      "   -0.12150671]\n",
      "  [        nan -0.12643573  0.00816614 ... -0.07696038 -0.01568983\n",
      "   -0.12769936]]]\n",
      "Labels:\n",
      "[[ 0.022387 -0.032147]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 10\n",
      "Video Name: ('SEW1106',), Timestamp: tensor([16.6600], dtype=torch.float64)\n",
      "Batch 10\n",
      "Video Features (first 3 rows):\n",
      "[[[ 2.3917001e-02  5.8415495e-05 -4.9541797e-04 ...  4.8891077e-05\n",
      "   -9.6239334e-01 -2.6841360e-04]\n",
      "  [ 2.4767000e-02  5.6421490e-05 -4.2845693e-04 ...  5.8798596e-05\n",
      "   -9.7317457e-01 -2.2147833e-04]\n",
      "  [ 2.5201000e-02  5.5691187e-05 -4.6573134e-04 ...  5.0178907e-05\n",
      "   -9.6799332e-01 -3.2249451e-04]\n",
      "  ...\n",
      "  [-2.3373600e-02  5.6388966e-05 -4.4419730e-04 ...  5.3123287e-05\n",
      "   -9.6959299e-01 -2.6687016e-04]\n",
      "  [-2.3373600e-02  5.6388966e-05 -4.4419730e-04 ...  5.3123287e-05\n",
      "   -9.6959299e-01 -2.6687016e-04]\n",
      "  [-2.3373600e-02  5.6388966e-05 -4.4419730e-04 ...  5.3123287e-05\n",
      "   -9.6959299e-01 -2.6687016e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan  0.00580218 -0.01506691 ... -0.03030249  0.02857053\n",
      "   -0.00335227]\n",
      "  [        nan  0.00941804  0.01024044 ... -0.15077712  0.02480367\n",
      "    0.05411247]]]\n",
      "Labels:\n",
      "[[-0.029416  -0.0233736]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SynchronizedAudioVideoDataset(Dataset):\n",
    "    def __init__(self, video_df, audio_df, window_length=2, step=1, max_frames=None): #3Frames per second, max amount frames = window_length*3\n",
    "        self.video_df = video_df\n",
    "        self.audio_df = audio_df\n",
    "        self.window_length = window_length\n",
    "        self.step = step\n",
    "        self.max_frames = max_frames\n",
    "        self.data = self._synchronize()\n",
    "        #step всегда пол окна, кроме случая с 1 сек, потому что аудио извлечено с шагом в секунду и нет смысла брать шаг 1.5 для шага модальностей\n",
    "\n",
    "    def _extract_video_id(self, path):\n",
    "        # This function extracts the video ID from the video file path.\n",
    "        return path.split('/')[-1].split('_')[0]\n",
    "        \n",
    "    def _synchronize(self):\n",
    "        synchronized_data = []\n",
    "        if self.max_frames is None:\n",
    "            self.max_frames = self._calculate_max_frames() #ensures that all video segments in the dataset have a uniform length.\n",
    "\n",
    "        video_ids = self.video_df['path'].apply(self._extract_video_id).unique() #retrieves unique video IDs from the video dataframe's file paths.\n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].apply(lambda x: self._extract_video_id(x) == video_id)]#test\n",
    "            audio_data = self.audio_df[self.audio_df['filename'].str.contains(video_id)]\n",
    "\n",
    "            start_time = 0\n",
    "            \"\"\"\n",
    "            - window of time defined by start_time and end_time (where end_time = start_time + self.window_length)\n",
    "            - video segments are selected based on their timestamps being within this window. Audio segments are chosen if their start and end timesteps fall within the window\n",
    "            - if selected video segment has less frames than self.max_frames, additional rows (copies of the last row) are appended to match self.max_frames\n",
    "            - labels for arousal and valence are taken from the last row of the windowed video data\n",
    "            \"\"\"\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)] #here smth can be wrong, check\n",
    "                #в большинстве случаев должно быть 6 фреймов в окне\n",
    "                # shape video , shape audio, timestep audio/video, labels\n",
    "                window_audio_data = audio_data[(audio_data['start_timestep'] >= start_time) & (audio_data['end_timestep'] <= end_time)] #print timesteps\n",
    "\n",
    "                if len(window_video_data) > 0 and len(window_audio_data) > 0:\n",
    "                    if len(window_video_data) < self.max_frames:\n",
    "                        additional_rows = self.max_frames - len(window_video_data)\n",
    "                        last_row = window_video_data.iloc[-1:].copy()\n",
    "                        for _ in range(additional_rows):\n",
    "                            window_video_data = pd.concat([window_video_data, last_row], ignore_index=True)\n",
    "                \n",
    "                #assert len(window_video_data)==int(self.window_length*3) вылетает ошибка сразу если не тру\n",
    "\n",
    "                    labels = window_video_data.iloc[-1][['arousal', 'valence']].values\n",
    "                    video_features = window_video_data.iloc[:, 3:].values #убрать arousal valence из фич, потому что они в лейблах\n",
    "                    audio_features = window_audio_data.iloc[:, 5:].values #выбросить пустую колонку features\n",
    "                    #распечатать все что сформировала \n",
    "                    # какие у видео и аудио начало и конец таймстеп, сколько кадров и какие лейблы, первые 10 итераций\n",
    "\n",
    "                    # Here: extract video_name and timestamp for each sample\n",
    "                    video_name = video_id\n",
    "                    timestamp = window_video_data.iloc[-1]['timestamp']\n",
    "\n",
    "                    synchronized_data.append((video_features, audio_features, labels, video_name, timestamp))\n",
    "\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "\n",
    "        return synchronized_data # contains tuples of synchronized video and audio features along with their labels, names, and timestamps\n",
    "\n",
    "\n",
    "    def _calculate_max_frames(self):\n",
    "        \"\"\"\n",
    "        Calculates the maximum number of frames within any window across all videos.\n",
    "        :return: Maximum number of frames within a window.\n",
    "        \"\"\"\n",
    "        max_frames = 0\n",
    "        video_ids = self.video_df['path'].apply(lambda x: x.split('/')[-2]).unique()\n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].str.contains(video_id)]\n",
    "            start_time = 0\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)]\n",
    "                max_frames = max(max_frames, len(window_video_data))\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "        return max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single item from the dataset by index. It ensures that video and audio features are converted to tensors of type float32 and\n",
    "        labels are processed to ensure they're in a consistent format before returning them along with the video name and timestamp.\n",
    "        \"\"\"\n",
    "        video_features, audio_features, labels, video_name, timestamp = self.data[idx]\n",
    "    \n",
    "        # Ensure labels are in a consistent format\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "        video_features_tensor = torch.tensor(video_features, dtype=torch.float32)\n",
    "        audio_features_tensor = torch.tensor(audio_features, dtype=torch.float32)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        print(f\"Video features type: {type(video_features)}, shape: {video_features.shape}\")\n",
    "        print(f\"Audio features type: {type(audio_features)}, shape: {audio_features.shape}\")\n",
    "        print(f\"Labels type: {type(labels)}, shape: {labels.shape}\")\n",
    "\n",
    "        return video_features_tensor, audio_features_tensor, labels_tensor, video_name, timestamp\n",
    "\n",
    "\n",
    "# Load video and audio data\n",
    "video_train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "video_dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "video_test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "audio_train_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_train.csv')\n",
    "audio_dev_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_dev.csv')\n",
    "audio_test_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_test.csv')\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = SynchronizedAudioVideoDataset(video_train_df, audio_train_df)\n",
    "dev_dataset = SynchronizedAudioVideoDataset(video_dev_df, audio_dev_df)\n",
    "test_dataset = SynchronizedAudioVideoDataset(video_test_df, audio_test_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 1  # For demonstration\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #убраить шафл и проверить вручную!\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Assuming you have your DataLoader setup as before\n",
    "for i, (video_features, audio_features, labels, video_name, timestamp) in enumerate(train_loader):\n",
    "    if i >= 10:  # Just to limit the output to the first 10 batches\n",
    "        break\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Video Name: {video_name}, Timestamp: {timestamp}\")    \n",
    "    # Convert tensors to numpy for easy slicing and displaying\n",
    "    video_features_np = video_features.numpy()\n",
    "    audio_features_np = audio_features.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "    \n",
    "    # Print the first few rows of each. Adjust the number of rows as needed\n",
    "    num_rows_to_display = 3  # for example, to display the first 3 rows\n",
    "    \n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Video Features (first {num_rows_to_display} rows):\")\n",
    "    print(video_features_np[:num_rows_to_display])\n",
    "    \n",
    "    print(f\"Audio Features (first {num_rows_to_display} rows):\")\n",
    "    # Note: If the second dimension represents a time or sequence dimension, you may need to adjust this\n",
    "    print(audio_features_np[:, :num_rows_to_display])  # Assuming the first dimension is batch\n",
    "    \n",
    "    print(\"Labels:\")\n",
    "    print(labels_np)  # Labels might be just one per sample, depending on your data structure\n",
    "    print(\"\\n----------\\n\")\n",
    "    # why \"shape: (384, 257) \" 384 не может быть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fbc349-b9f0-4531-9a0e-297432411ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 1: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[ 0.0877588 -0.0935914]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 2: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.2031382 0.0109242]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 3: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.1340938 0.0669474]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 4: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.233499 0.268689]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 5: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.114923  0.0553804]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 6: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.0668214 0.015141 ]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 7: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[ 0.123937  -0.1112222]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 8: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.062235 0.159934]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 9: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[0.1213252 0.       ]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Sample 10: Video features shape: torch.Size([1, 384, 257]), Audio features shape: torch.Size([1, 2, 769]), Labels: [[ 0.135057  -0.1952266]]\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Adjusted class to consider the path difference\n",
    "class SynchronizedAudioVideoDataset(Dataset):\n",
    "    def __init__(self, video_df, audio_df, window_length=2, step=1, max_frames=None):\n",
    "        self.video_df = video_df\n",
    "        self.audio_df = audio_df\n",
    "        self.window_length = window_length\n",
    "        self.step = step\n",
    "        self.max_frames = max_frames\n",
    "        self.data = self._synchronize()\n",
    "\n",
    "    def _extract_video_id(self, path):\n",
    "        # This function extracts the video ID from the video file path.\n",
    "        # Adjust the slicing as per your directory structure if needed.\n",
    "        return path.split('/')[-1].split('_')[0]\n",
    "\n",
    "    def _synchronize(self):\n",
    "        synchronized_data = []\n",
    "        if self.max_frames is None:\n",
    "            self.max_frames = self._calculate_max_frames()\n",
    "\n",
    "        video_ids = self.video_df['path'].apply(self._extract_video_id).unique()\n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].apply(lambda x: self._extract_video_id(x) == video_id)]\n",
    "            audio_data = self.audio_df[self.audio_df['filename'].str.contains(video_id)]\n",
    "\n",
    "            start_time = 0\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)]\n",
    "                window_audio_data = audio_data[(audio_data['start_timestep'] >= start_time) & (audio_data['end_timestep'] <= end_time)]\n",
    "\n",
    "                if len(window_video_data) > 0 and len(window_audio_data) > 0:\n",
    "                    if len(window_video_data) < self.max_frames:\n",
    "                        additional_rows = self.max_frames - len(window_video_data)\n",
    "                        last_row = window_video_data.iloc[-1:].copy()\n",
    "                        for _ in range(additional_rows):\n",
    "                            window_video_data = pd.concat([window_video_data, last_row], ignore_index=True)\n",
    "                    \n",
    "                    labels = window_video_data.iloc[-1][['arousal', 'valence']].values\n",
    "                    video_features = window_video_data.iloc[:, 3:].values\n",
    "                    audio_features = window_audio_data.iloc[:, 5:].values\n",
    "                    \n",
    "                    synchronized_data.append((video_features, audio_features, labels))\n",
    "\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "\n",
    "        return synchronized_data\n",
    "\n",
    "    def _calculate_max_frames(self):\n",
    "        \"\"\"\n",
    "        Calculates the maximum number of frames within any window across all videos.\n",
    "        :return: Maximum number of frames within a window.\n",
    "        \"\"\"\n",
    "        max_frames = 0\n",
    "        video_ids = self.video_df['path'].apply(lambda x: x.split('/')[-2]).unique()\n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].str.contains(video_id)]\n",
    "            start_time = 0\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)]\n",
    "                max_frames = max(max_frames, len(window_video_data))\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "        return max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_features, audio_features, labels = self.data[idx]\n",
    "    \n",
    "        print(f\"Video features type: {type(video_features)}, shape: {video_features.shape}\")\n",
    "        print(f\"Audio features type: {type(audio_features)}, shape: {audio_features.shape}\")\n",
    "        print(f\"Labels type: {type(labels)}, shape: {labels.shape}\")\n",
    "\n",
    "        # Ensure video_features and audio_features are numpy arrays of type float\n",
    "        video_features = np.array(video_features, dtype=np.float32)\n",
    "        audio_features = np.array(audio_features, dtype=np.float32)\n",
    "    \n",
    "        # Convert labels to numpy array if it's not already\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "        return torch.tensor(video_features, dtype=torch.float), torch.tensor(audio_features, dtype=torch.float), torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Load video and audio data\n",
    "video_train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "video_dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "video_test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "audio_train_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_train.csv')\n",
    "audio_dev_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_dev.csv')\n",
    "audio_test_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_test.csv')\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = SynchronizedAudioVideoDataset(video_train_df, audio_train_df)\n",
    "dev_dataset = SynchronizedAudioVideoDataset(video_dev_df, audio_dev_df)\n",
    "test_dataset = SynchronizedAudioVideoDataset(video_test_df, audio_test_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 1  # For demonstration\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Display the first 10 entries from the train_loader\n",
    "for i, (video_features, audio_features, labels) in enumerate(train_loader):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"Sample {i+1}: Video features shape: {video_features.shape}, Audio features shape: {audio_features.shape}, Labels: {labels.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3085edd4-5898-4baf-97c0-e5cd239161a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4736/1304122245.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 1\n",
      "Video Features (first 3 rows):\n",
      "[[[ 2.4889860e-01  8.8315610e-05 -6.2006363e-04 ...  3.9475199e-05\n",
      "   -9.8073441e-01 -3.2977949e-04]\n",
      "  [ 2.2260000e-01  9.4982752e-05 -9.3289296e-04 ...  2.4347770e-05\n",
      "   -9.8099303e-01 -5.2966579e-04]\n",
      "  [ 1.8751600e-01  8.8167995e-05 -8.6004921e-04 ...  4.7251844e-05\n",
      "   -9.7213334e-01 -5.1216752e-04]\n",
      "  ...\n",
      "  [ 9.9471398e-02  7.8380086e-05 -9.7199652e-04 ...  6.0424798e-05\n",
      "   -9.1462880e-01 -5.3763820e-04]\n",
      "  [ 9.9471398e-02  7.8380086e-05 -9.7199652e-04 ...  6.0424798e-05\n",
      "   -9.1462880e-01 -5.3763820e-04]\n",
      "  [ 9.9471398e-02  7.8380086e-05 -9.7199652e-04 ...  6.0424798e-05\n",
      "   -9.1462880e-01 -5.3763820e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.02999436 -0.01172482 ... -0.09862999 -0.0093683\n",
      "   -0.13289516]\n",
      "  [        nan -0.0118871  -0.01024382 ... -0.17639372  0.02893298\n",
      "    0.01501615]]]\n",
      "Labels:\n",
      "[[0.1737794 0.0994714]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 2\n",
      "Video Features (first 3 rows):\n",
      "[[[ 1.1596200e-01  8.3023529e-05 -1.2443789e-03 ... -2.0542724e-05\n",
      "   -8.3075291e-01 -6.2452338e-04]\n",
      "  [ 1.1671320e-01  7.9457379e-05 -1.1011600e-03 ... -7.0085207e-06\n",
      "   -8.0229914e-01 -5.7237822e-04]\n",
      "  [ 1.1596200e-01  8.8273300e-05 -1.2473174e-03 ...  4.6038554e-06\n",
      "   -9.1997433e-01 -6.8403949e-04]\n",
      "  ...\n",
      "  [ 1.0970040e-01  8.2608844e-05 -1.5029036e-03 ...  1.8222732e-05\n",
      "   -9.3688124e-01 -7.8431435e-04]\n",
      "  [ 1.0970040e-01  8.2608844e-05 -1.5029036e-03 ...  1.8222732e-05\n",
      "   -9.3688124e-01 -7.8431435e-04]\n",
      "  [ 1.0970040e-01  8.2608844e-05 -1.5029036e-03 ...  1.8222732e-05\n",
      "   -9.3688124e-01 -7.8431435e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan  0.02641756  0.01534882 ... -0.13716082  0.03795599\n",
      "    0.04174314]\n",
      "  [        nan -0.21742299  0.03112669 ...  0.05088299  0.02836455\n",
      "   -0.07531484]]]\n",
      "Labels:\n",
      "[[0.1571882 0.1097004]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 3\n",
      "Video Features (first 3 rows):\n",
      "[[[ 1.8351199e-02  8.1399150e-05 -1.2513594e-03 ...  7.3002841e-05\n",
      "   -8.9704460e-01 -8.9237012e-04]\n",
      "  [ 1.7094400e-02  9.3685048e-05 -1.1538982e-03 ...  8.3928557e-05\n",
      "   -9.6956325e-01 -8.7166653e-04]\n",
      "  [ 1.8247999e-02  7.9163030e-05 -1.1681312e-03 ...  1.1157726e-04\n",
      "   -9.3299311e-01 -7.5311342e-04]\n",
      "  ...\n",
      "  [ 1.6884999e-02  8.5822583e-05 -1.2675072e-03 ...  9.5665971e-05\n",
      "   -9.6782774e-01 -7.2165619e-04]\n",
      "  [ 1.6884999e-02  8.5822583e-05 -1.2675072e-03 ...  9.5665971e-05\n",
      "   -9.6782774e-01 -7.2165619e-04]\n",
      "  [ 1.6884999e-02  8.5822583e-05 -1.2675072e-03 ...  9.5665971e-05\n",
      "   -9.6782774e-01 -7.2165619e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.06251837  0.0159986  ... -0.07512661  0.02078991\n",
      "   -0.07375142]\n",
      "  [        nan  0.00506587 -0.01195932 ... -0.06008154 -0.01032275\n",
      "    0.04663827]]]\n",
      "Labels:\n",
      "[[0.1262864 0.016885 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 4\n",
      "Video Features (first 3 rows):\n",
      "[[[ 4.4829600e-02  7.0710121e-05 -7.2043523e-04 ...  1.0363905e-04\n",
      "   -9.0358448e-01 -6.1703479e-04]\n",
      "  [ 3.1440999e-02  6.9753813e-05 -7.2293275e-04 ...  9.6339048e-05\n",
      "   -9.0161812e-01 -5.5343146e-04]\n",
      "  [ 2.5567001e-02  7.0971466e-05 -8.1374089e-04 ...  8.6236585e-05\n",
      "   -9.1051966e-01 -5.6363014e-04]\n",
      "  ...\n",
      "  [ 2.4676001e-02  6.8440393e-05 -9.0603589e-04 ...  8.7856279e-05\n",
      "   -8.4096181e-01 -5.9878331e-04]\n",
      "  [ 2.4676001e-02  6.8440393e-05 -9.0603589e-04 ...  8.7856279e-05\n",
      "   -8.4096181e-01 -5.9878331e-04]\n",
      "  [ 2.4676001e-02  6.8440393e-05 -9.0603589e-04 ...  8.7856279e-05\n",
      "   -8.4096181e-01 -5.9878331e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.12488163  0.00546485 ... -0.0590845  -0.01723214\n",
      "    0.0100482 ]\n",
      "  [        nan -0.03364174  0.0054855  ... -0.12313773  0.03001484\n",
      "    0.03439143]]]\n",
      "Labels:\n",
      "[[0.0290646 0.024676 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 5\n",
      "Video Features (first 3 rows):\n",
      "[[[-2.8899999e-03  7.3335330e-05 -1.2025543e-03 ...  5.9801761e-05\n",
      "   -8.5430676e-01 -6.2951603e-04]\n",
      "  [-2.9100000e-03  7.2359369e-05 -1.2433602e-03 ...  5.3943451e-05\n",
      "   -8.8902223e-01 -6.1307830e-04]\n",
      "  [-2.9100000e-03  7.1547693e-05 -1.1753849e-03 ...  4.8932208e-05\n",
      "   -8.8651240e-01 -6.0831982e-04]\n",
      "  ...\n",
      "  [ 9.4060004e-03  7.4638410e-05 -1.1210237e-03 ...  4.6517805e-05\n",
      "   -9.0579784e-01 -5.8030040e-04]\n",
      "  [ 9.4060004e-03  7.4638410e-05 -1.1210237e-03 ...  4.6517805e-05\n",
      "   -9.0579784e-01 -5.8030040e-04]\n",
      "  [ 9.4060004e-03  7.4638410e-05 -1.1210237e-03 ...  4.6517805e-05\n",
      "   -9.0579784e-01 -5.8030040e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.13661528  0.0156615  ...  0.00513851 -0.00751219\n",
      "    0.00335487]\n",
      "  [        nan -0.13755593  0.01680741 ...  0.01271218 -0.00780157\n",
      "    0.00341899]]]\n",
      "Labels:\n",
      "[[0.0670504 0.009406 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 6\n",
      "Video Features (first 3 rows):\n",
      "[[[-1.3362101e-01  7.5037089e-05 -9.6747710e-04 ...  4.7567959e-05\n",
      "   -9.5603281e-01 -8.0722751e-04]\n",
      "  [-1.1533160e-01  7.7175144e-05 -1.2165355e-03 ...  5.8469228e-05\n",
      "   -9.7560459e-01 -7.7852421e-04]\n",
      "  [-1.0432760e-01  8.0642465e-05 -1.1212501e-03 ...  7.0747141e-05\n",
      "   -9.4578588e-01 -8.0326368e-04]\n",
      "  ...\n",
      "  [-9.5186003e-02  7.2223404e-05 -8.4797287e-04 ...  6.4794483e-05\n",
      "   -9.5066422e-01 -7.1221805e-04]\n",
      "  [-9.5186003e-02  7.2223404e-05 -8.4797287e-04 ...  6.4794483e-05\n",
      "   -9.5066422e-01 -7.1221805e-04]\n",
      "  [-9.5186003e-02  7.2223404e-05 -8.4797287e-04 ...  6.4794483e-05\n",
      "   -9.5066422e-01 -7.1221805e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.13600594 -0.02157615 ...  0.01872576 -0.0279187\n",
      "   -0.01514719]\n",
      "  [        nan  0.01311466 -0.01648311 ... -0.01165159  0.00368648\n",
      "   -0.04521809]]]\n",
      "Labels:\n",
      "[[ 0.059719 -0.095186]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 7\n",
      "Video Features (first 3 rows):\n",
      "[[[-7.1040000e-04  7.1940245e-05 -1.0282035e-03 ...  2.1310540e-05\n",
      "   -8.8670075e-01 -5.8854994e-04]\n",
      "  [ 0.0000000e+00  7.0622977e-05 -9.6464029e-04 ...  3.0882096e-05\n",
      "   -8.5417020e-01 -5.7842769e-04]\n",
      "  [ 0.0000000e+00  7.1515213e-05 -9.4410795e-04 ...  3.0794876e-05\n",
      "   -8.8079238e-01 -5.4799503e-04]\n",
      "  ...\n",
      "  [ 0.0000000e+00  7.1067829e-05 -9.1046299e-04 ...  2.8054543e-05\n",
      "   -9.0068078e-01 -5.6101260e-04]\n",
      "  [ 0.0000000e+00  7.1067829e-05 -9.1046299e-04 ...  2.8054543e-05\n",
      "   -9.0068078e-01 -5.6101260e-04]\n",
      "  [ 0.0000000e+00  7.1067829e-05 -9.1046299e-04 ...  2.8054543e-05\n",
      "   -9.0068078e-01 -5.6101260e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.11931859  0.01050648 ... -0.05646099 -0.02085106\n",
      "   -0.13020322]\n",
      "  [        nan -0.12947361  0.00841104 ... -0.08006977 -0.0165333\n",
      "   -0.12663628]]]\n",
      "Labels:\n",
      "[[0.080864 0.      ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 8\n",
      "Video Features (first 3 rows):\n",
      "[[[-4.4142520e-01  6.3077860e-05 -6.6374190e-04 ...  9.3122413e-05\n",
      "   -8.5582989e-01 -4.9317599e-04]\n",
      "  [-4.4093081e-01  7.1278460e-05 -7.2699517e-04 ...  8.4517182e-05\n",
      "   -9.5985597e-01 -4.6928227e-04]\n",
      "  [-4.4068119e-01  6.8192123e-05 -8.0073572e-04 ...  9.0022397e-05\n",
      "   -9.1165316e-01 -5.6733814e-04]\n",
      "  ...\n",
      "  [-4.4067001e-01  7.0752496e-05 -8.7653555e-04 ...  1.0256774e-04\n",
      "   -9.3694085e-01 -6.3063588e-04]\n",
      "  [-4.4067001e-01  7.0752496e-05 -8.7653555e-04 ...  1.0256774e-04\n",
      "   -9.3694085e-01 -6.3063588e-04]\n",
      "  [-4.4067001e-01  7.0752496e-05 -8.7653555e-04 ...  1.0256774e-04\n",
      "   -9.3694085e-01 -6.3063588e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[           nan -1.8001005e-02  1.5633384e-02 ... -8.6646624e-02\n",
      "    3.9188996e-02 -3.8939342e-03]\n",
      "  [           nan -3.5887752e-02  1.6962226e-02 ...  8.2190847e-05\n",
      "    1.7186394e-02 -1.4711134e-01]]]\n",
      "Labels:\n",
      "[[ 0.334635 -0.44067 ]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 9\n",
      "Video Features (first 3 rows):\n",
      "[[[-3.7716001e-02  7.5418611e-05 -1.1557798e-03 ...  2.1343576e-05\n",
      "   -9.5833409e-01 -7.0410536e-04]\n",
      "  [-3.8660798e-02  7.2674738e-05 -1.1208600e-03 ...  3.7013197e-05\n",
      "   -9.5140457e-01 -6.6556275e-04]\n",
      "  [-7.2535999e-02  8.2543702e-05 -1.1871249e-03 ...  2.6926753e-05\n",
      "   -9.2584103e-01 -9.2611415e-04]\n",
      "  ...\n",
      "  [-4.0105201e-02  7.8054494e-05 -1.1383933e-03 ...  2.2046839e-05\n",
      "   -9.3457979e-01 -8.6159562e-04]\n",
      "  [-4.0105201e-02  7.8054494e-05 -1.1383933e-03 ...  2.2046839e-05\n",
      "   -9.3457979e-01 -8.6159562e-04]\n",
      "  [-4.0105201e-02  7.8054494e-05 -1.1383933e-03 ...  2.2046839e-05\n",
      "   -9.3457979e-01 -8.6159562e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.04133209 -0.00476174 ... -0.02119997 -0.01022851\n",
      "   -0.03800718]\n",
      "  [        nan -0.07851682  0.0037782  ... -0.02550811  0.00480055\n",
      "   -0.0176397 ]]]\n",
      "Labels:\n",
      "[[-0.1873452 -0.0401052]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n",
      "Batch 10\n",
      "Video Features (first 3 rows):\n",
      "[[[ 3.6096200e-02  7.8965422e-05 -1.2681581e-03 ...  1.7735210e-05\n",
      "   -9.1050881e-01 -7.3094969e-04]\n",
      "  [ 3.5633601e-02  6.8574416e-05 -1.2290971e-03 ...  1.6799202e-05\n",
      "   -8.8585013e-01 -5.9311715e-04]\n",
      "  [ 3.7223801e-02  6.9616042e-05 -9.5264940e-04 ...  2.7619246e-05\n",
      "   -9.5035458e-01 -4.9013511e-04]\n",
      "  ...\n",
      "  [ 4.3570802e-02  7.3426338e-05 -1.0965839e-03 ...  3.6601994e-06\n",
      "   -8.5195190e-01 -6.1621919e-04]\n",
      "  [ 4.3570802e-02  7.3426338e-05 -1.0965839e-03 ...  3.6601994e-06\n",
      "   -8.5195190e-01 -6.1621919e-04]\n",
      "  [ 4.3570802e-02  7.3426338e-05 -1.0965839e-03 ...  3.6601994e-06\n",
      "   -8.5195190e-01 -6.1621919e-04]]]\n",
      "Audio Features (first 3 rows):\n",
      "[[[        nan -0.04477328 -0.00406545 ... -0.05299769  0.05539138\n",
      "   -0.00931462]\n",
      "  [        nan  0.015913    0.00159229 ... -0.04200086  0.02313264\n",
      "    0.01294123]]]\n",
      "Labels:\n",
      "[[0.052526  0.0435708]]\n",
      "\n",
      "----------\n",
      "\n",
      "Video features type: <class 'numpy.ndarray'>, shape: (384, 257)\n",
      "Audio features type: <class 'numpy.ndarray'>, shape: (2, 769)\n",
      "Labels type: <class 'numpy.ndarray'>, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Adjusted class to consider the path difference\n",
    "class SynchronizedAudioVideoDataset(Dataset):\n",
    "    def __init__(self, video_df, audio_df, window_length=2, step=1, max_frames=None):\n",
    "        self.video_df = video_df\n",
    "        self.audio_df = audio_df\n",
    "        self.window_length = window_length\n",
    "        self.step = step\n",
    "        self.max_frames = max_frames\n",
    "        self.data = self._synchronize()\n",
    "\n",
    "    def _extract_video_id(self, path):\n",
    "        # This function extracts the video ID from the video file path.\n",
    "        # Adjust the slicing as per your directory structure if needed.\n",
    "        return path.split('/')[-1].split('_')[0]\n",
    "\n",
    "    def _synchronize(self):\n",
    "        synchronized_data = []\n",
    "        if self.max_frames is None:\n",
    "            self.max_frames = self._calculate_max_frames()\n",
    "\n",
    "        video_ids = self.video_df['path'].apply(self._extract_video_id).unique()\n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].apply(lambda x: self._extract_video_id(x) == video_id)]\n",
    "            audio_data = self.audio_df[self.audio_df['filename'].str.contains(video_id)]\n",
    "\n",
    "            start_time = 0\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)]\n",
    "                window_audio_data = audio_data[(audio_data['start_timestep'] >= start_time) & (audio_data['end_timestep'] <= end_time)]\n",
    "\n",
    "                if len(window_video_data) > 0 and len(window_audio_data) > 0:\n",
    "                    if len(window_video_data) < self.max_frames:\n",
    "                        additional_rows = self.max_frames - len(window_video_data)\n",
    "                        last_row = window_video_data.iloc[-1:].copy()\n",
    "                        for _ in range(additional_rows):\n",
    "                            window_video_data = pd.concat([window_video_data, last_row], ignore_index=True)\n",
    "                    \n",
    "                    labels = window_video_data.iloc[-1][['arousal', 'valence']].values\n",
    "                    video_features = window_video_data.iloc[:, 3:].values\n",
    "                    audio_features = window_audio_data.iloc[:, 5:].values\n",
    "                    \n",
    "                    synchronized_data.append((video_features, audio_features, labels))\n",
    "\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "\n",
    "        return synchronized_data\n",
    "\n",
    "    def _calculate_max_frames(self):\n",
    "        \"\"\"\n",
    "        Calculates the maximum number of frames within any window across all videos.\n",
    "        :return: Maximum number of frames within a window.\n",
    "        \"\"\"\n",
    "        max_frames = 0\n",
    "        video_ids = self.video_df['path'].apply(lambda x: x.split('/')[-2]).unique()\n",
    "        for video_id in video_ids:\n",
    "            video_data = self.video_df[self.video_df['path'].str.contains(video_id)]\n",
    "            start_time = 0\n",
    "            while True:\n",
    "                end_time = start_time + self.window_length\n",
    "                window_video_data = video_data[(video_data['timestamp'] >= start_time) & (video_data['timestamp'] < end_time)]\n",
    "                max_frames = max(max_frames, len(window_video_data))\n",
    "                start_time += self.step\n",
    "                if start_time + self.window_length > video_data['timestamp'].max():\n",
    "                    break\n",
    "        return max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_features, audio_features, labels = self.data[idx]\n",
    "    \n",
    "        print(f\"Video features type: {type(video_features)}, shape: {video_features.shape}\")\n",
    "        print(f\"Audio features type: {type(audio_features)}, shape: {audio_features.shape}\")\n",
    "        print(f\"Labels type: {type(labels)}, shape: {labels.shape}\")\n",
    "\n",
    "        # Ensure video_features and audio_features are numpy arrays of type float\n",
    "        video_features = np.array(video_features, dtype=np.float32)\n",
    "        audio_features = np.array(audio_features, dtype=np.float32)\n",
    "    \n",
    "        # Convert labels to numpy array if it's not already\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "        return torch.tensor(video_features, dtype=torch.float), torch.tensor(audio_features, dtype=torch.float), torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Load video and audio data\n",
    "video_train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "video_dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "video_test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "audio_train_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_train.csv')\n",
    "audio_dev_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_dev.csv')\n",
    "audio_test_df = pd.read_csv('1sec/SEWA_features_wav2vec_1_seconds_test.csv')\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = SynchronizedAudioVideoDataset(video_train_df, audio_train_df)\n",
    "dev_dataset = SynchronizedAudioVideoDataset(video_dev_df, audio_dev_df)\n",
    "test_dataset = SynchronizedAudioVideoDataset(video_test_df, audio_test_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 1  # For demonstration\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Assuming you have your DataLoader setup as before\n",
    "for i, (video_features, audio_features, labels) in enumerate(train_loader):\n",
    "    if i >= 10:  # Just to limit the output to the first 10 batches\n",
    "        break\n",
    "    \n",
    "    # Convert tensors to numpy for easy slicing and displaying\n",
    "    video_features_np = video_features.numpy()\n",
    "    audio_features_np = audio_features.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "    \n",
    "    # Print the first few rows of each. Adjust the number of rows as needed\n",
    "    num_rows_to_display = 3  # for example, to display the first 3 rows\n",
    "    \n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Video Features (first {num_rows_to_display} rows):\")\n",
    "    print(video_features_np[:num_rows_to_display])\n",
    "    \n",
    "    print(f\"Audio Features (first {num_rows_to_display} rows):\")\n",
    "    # Note: If the second dimension represents a time or sequence dimension, you may need to adjust this\n",
    "    print(audio_features_np[:, :num_rows_to_display])  # Assuming the first dimension is batch\n",
    "    \n",
    "    print(\"Labels:\")\n",
    "    print(labels_np)  # Labels might be just one per sample, depending on your data structure\n",
    "    print(\"\\n----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47bc7f8-0822-4faf-addd-a6a4cfcf341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load a dataset\n",
    "def load_dataset(audio_path, video_path):\n",
    "    audio_df = pd.read_csv(audio_path)\n",
    "    video_df = pd.read_csv(video_path)\n",
    "    # Ensure the timestamp is rounded for proper matching\n",
    "    video_df['matched_audio_start'] = video_df['timestamp'].apply(lambda x: int(x))\n",
    "    return audio_df, video_df\n",
    "\n",
    "# Function to ensure data types match and prevent many-to-many joins\n",
    "def synchronize_and_merge(audio_df, video_df):\n",
    "    # Convert timestamps in both dataframes to a consistent format and type\n",
    "    audio_df['start_timestep'] = audio_df['start_timestep'].apply(lambda x: round(x, 2))\n",
    "    video_df['matched_audio_start'] = video_df['timestamp'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Ensure both columns are of the same type\n",
    "    audio_df['start_timestep'] = audio_df['start_timestep'].astype(float)\n",
    "    video_df['matched_audio_start'] = video_df['matched_audio_start'].astype(float)\n",
    "\n",
    "    # Merge using an inner join to ensure only matching rows are included\n",
    "    merged_df = pd.merge(audio_df, video_df, left_on='start_timestep', right_on='matched_audio_start', how='inner')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Paths to your datasets\n",
    "dataset_paths = {\n",
    "    \"train\": (\"1sec/SEWA_features_wav2vec_1_seconds_train.csv\", \"SEWA_radiant_fog_160_train.csv\"),\n",
    "    \"dev\": (\"1sec/SEWA_features_wav2vec_1_seconds_dev.csv\", \"SEWA_radiant_fog_160_dev.csv\"),\n",
    "    \"test\": (\"1sec/SEWA_features_wav2vec_1_seconds_test.csv\", \"SEWA_radiant_fog_160_test.csv\")\n",
    "}\n",
    "\n",
    "# Process and save each dataset\n",
    "for set_name, (audio_path, video_path) in dataset_paths.items():\n",
    "    audio_df, video_df = load_dataset(audio_path, video_path)\n",
    "    merged_df = synchronize_and_merge(audio_df, video_df)\n",
    "    # Save the synchronized and merged dataset\n",
    "    merged_df.to_csv(f'SynchronizedData-Fusion/synchronized_{set_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6c98e-7c8e-4ce2-816b-c6d1cf4a2561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5000/3053155940.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def synchronize_audio_video(audio_df, video_df):\n",
    "    # Round video timestamps for easier matching\n",
    "    video_df['rounded_timestamp'] = video_df['timestamp'].round()\n",
    "    \n",
    "    # Prepare the audio dataframe by creating a key for easier merging\n",
    "    audio_df['merge_key'] = audio_df['start_timestep'].astype(int)\n",
    "    \n",
    "    # Merge based on the rounded timestamp and the new audio merge key\n",
    "    merged_df = pd.merge(video_df, audio_df, left_on='rounded_timestamp', right_on='merge_key', how='inner')\n",
    "    \n",
    "    # Drop unnecessary columns if needed\n",
    "    merged_df.drop(['rounded_timestamp', 'merge_key'], axis=1, inplace=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Paths to your datasets\n",
    "audio_train_path = '1sec/SEWA_features_wav2vec_1_seconds_train.csv'\n",
    "audio_dev_path = '1sec/SEWA_features_wav2vec_1_seconds_dev.csv'\n",
    "audio_test_path = '1sec/SEWA_features_wav2vec_1_seconds_test.csv'\n",
    "\n",
    "video_train_path = 'SEWA_radiant_fog_160_train.csv'\n",
    "video_dev_path = 'SEWA_radiant_fog_160_dev.csv'\n",
    "video_test_path = 'SEWA_radiant_fog_160_test.csv'\n",
    "\n",
    "# Load the datasets\n",
    "audio_train = pd.read_csv(audio_train_path)\n",
    "audio_dev = pd.read_csv(audio_dev_path)\n",
    "audio_test = pd.read_csv(audio_test_path)\n",
    "\n",
    "video_train = pd.read_csv(video_train_path)\n",
    "video_dev = pd.read_csv(video_dev_path)\n",
    "video_test = pd.read_csv(video_test_path)\n",
    "\n",
    "# Synchronize and merge the datasets\n",
    "merged_train = synchronize_audio_video(audio_train, video_train)\n",
    "merged_dev = synchronize_audio_video(audio_dev, video_dev)\n",
    "merged_test = synchronize_audio_video(audio_test, video_test)\n",
    "\n",
    "# Save the synchronized and merged datasets\n",
    "merged_train.to_csv('SynchronizedData-Fusion/merged_train.csv', index=False)\n",
    "merged_dev.to_csv('SynchronizedData-Fusion/merged_dev.csv', index=False)\n",
    "merged_test.to_csv('SynchronizedData-Fusion/merged_test.csv', index=False)\n",
    "\n",
    "print(\"Synchronization and merging complete. Files saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

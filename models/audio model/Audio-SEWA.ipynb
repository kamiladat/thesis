{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7292fb-7c72-420f-bc28-5a9ba401a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal - Dev MSE: 0.011893248013856774 Dev RMSE: 0.10905616907748399 Test MSE: 0.03340598663453017 Test RMSE: 0.18277304679446083\n"
     ]
    }
   ],
   "source": [
    "#SVR 1 sec TEST ONLY AROUSAL \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def load_and_preprocess_dataset(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    features_start_col = data.columns.get_loc(\"x_0\")\n",
    "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
    "    y_arousal = data['arousal'].values\n",
    "    return X, y_arousal\n",
    "\n",
    "# Scale features (function)\n",
    "def scale_features(X_train, X_dev, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_dev_scaled = scaler.transform(X_dev)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
    "\n",
    "# SVR Grid Search (function)\n",
    "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
    "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
    "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
    "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model (function)\n",
    "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
    "    # Dev set\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
    "    rmse_dev = sqrt(mse_dev)\n",
    "    # Test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
    "\n",
    "# Paths to datasets\n",
    "train_file = \"1sec/SEWA_features_wav2vec_1_seconds_train.csv\"\n",
    "dev_file = \"1sec/SEWA_features_wav2vec_1_seconds_dev.csv\"\n",
    "test_file = \"1sec/SEWA_features_wav2vec_1_seconds_test.csv\"\n",
    "\n",
    "# Load and preprocess datasets\n",
    "X_train, y_arousal_train= load_and_preprocess_dataset(train_file)\n",
    "X_dev, y_arousal_dev= load_and_preprocess_dataset(dev_file)\n",
    "X_test, y_arousal_test= load_and_preprocess_dataset(test_file)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
    "\n",
    "# SVR parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Arousal Model\n",
    "best_svr_arousal = svr_grid_search(X_train_scaled, y_arousal_train, X_dev_scaled, y_arousal_dev, param_grid)\n",
    "mse_arousal_dev, rmse_arousal_dev, mse_arousal_test, rmse_arousal_test = evaluate_model(best_svr_arousal, X_dev_scaled, y_arousal_dev, X_test_scaled, y_arousal_test)\n",
    "\n",
    "# Results\n",
    "print(\"Arousal - Dev MSE:\", mse_arousal_dev, \"Dev RMSE:\", rmse_arousal_dev, \"Test MSE:\", mse_arousal_test, \"Test RMSE:\", rmse_arousal_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458f7c8-d515-433d-b2c7-7c5f150cb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 sec only val\n",
    "#SVR 1 sec \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def load_and_preprocess_dataset(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    features_start_col = data.columns.get_loc(\"x_0\")\n",
    "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
    "    y_valence = data['valence'].values\n",
    "    return X, y_valence\n",
    "\n",
    "# Scale features (function)\n",
    "def scale_features(X_train, X_dev, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_dev_scaled = scaler.transform(X_dev)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
    "\n",
    "# SVR Grid Search (function)\n",
    "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
    "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
    "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
    "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model (function)\n",
    "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
    "    # Dev set\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
    "    rmse_dev = sqrt(mse_dev)\n",
    "    # Test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
    "\n",
    "# Paths to datasets\n",
    "train_file = \"1sec/SEWA_features_wav2vec_1_seconds_train.csv\"\n",
    "dev_file = \"1sec/SEWA_features_wav2vec_1_seconds_dev.csv\"\n",
    "test_file = \"1sec/SEWA_features_wav2vec_1_seconds_test.csv\"\n",
    "\n",
    "# Load and preprocess datasets\n",
    "X_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
    "X_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
    "X_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
    "\n",
    "# SVR parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Valence Model\n",
    "best_svr_valence = svr_grid_search(X_train_scaled, y_valence_train, X_dev_scaled, y_valence_dev, param_grid)\n",
    "mse_valence_dev, rmse_valence_dev, mse_valence_test, rmse_valence_test = evaluate_model(best_svr_valence, X_dev_scaled, y_valence_dev, X_test_scaled, y_valence_test)\n",
    "\n",
    "# Results\n",
    "print(\"Valence - Dev MSE:\", mse_valence_dev, \"Dev RMSE:\", rmse_valence_dev, \"Test MSE:\", mse_valence_test, \"Test RMSE:\", rmse_valence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f2156-215a-4717-888d-f02b8ac9f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1127/1041356422.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#SVR 1 sec \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def load_and_preprocess_dataset(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    features_start_col = data.columns.get_loc(\"x_0\")\n",
    "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
    "    y_arousal = data['arousal'].values\n",
    "    y_valence = data['valence'].values\n",
    "    return X, y_arousal, y_valence\n",
    "\n",
    "# Scale features (function)\n",
    "def scale_features(X_train, X_dev, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_dev_scaled = scaler.transform(X_dev)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
    "\n",
    "# SVR Grid Search (function)\n",
    "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
    "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
    "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
    "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model (function)\n",
    "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
    "    # Dev set\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
    "    rmse_dev = sqrt(mse_dev)\n",
    "    # Test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
    "\n",
    "# Paths to datasets\n",
    "train_file = \"1sec/SEWA_features_wav2vec_1_seconds_train.csv\"\n",
    "dev_file = \"1sec/SEWA_features_wav2vec_1_seconds_dev.csv\"\n",
    "test_file = \"1sec/SEWA_features_wav2vec_1_seconds_test.csv\"\n",
    "\n",
    "# Load and preprocess datasets\n",
    "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
    "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
    "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
    "\n",
    "# SVR parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Arousal Model\n",
    "best_svr_arousal = svr_grid_search(X_train_scaled, y_arousal_train, X_dev_scaled, y_arousal_dev, param_grid)\n",
    "mse_arousal_dev, rmse_arousal_dev, mse_arousal_test, rmse_arousal_test = evaluate_model(best_svr_arousal, X_dev_scaled, y_arousal_dev, X_test_scaled, y_arousal_test)\n",
    "\n",
    "# Valence Model\n",
    "best_svr_valence = svr_grid_search(X_train_scaled, y_valence_train, X_dev_scaled, y_valence_dev, param_grid)\n",
    "mse_valence_dev, rmse_valence_dev, mse_valence_test, rmse_valence_test = evaluate_model(best_svr_valence, X_dev_scaled, y_valence_dev, X_test_scaled, y_valence_test)\n",
    "\n",
    "# Results\n",
    "print(\"Arousal - Dev MSE:\", mse_arousal_dev, \"Dev RMSE:\", rmse_arousal_dev, \"Test MSE:\", mse_arousal_test, \"Test RMSE:\", rmse_arousal_test)\n",
    "print(\"Valence - Dev MSE:\", mse_valence_dev, \"Dev RMSE:\", rmse_valence_dev, \"Test MSE:\", mse_valence_test, \"Test RMSE:\", rmse_valence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b37abc-3139-4461-bb85-7dbc3f4545a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR 2 sec \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def load_and_preprocess_dataset(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    features_start_col = data.columns.get_loc(\"x_0\")\n",
    "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
    "    y_arousal = data['arousal'].values\n",
    "    y_valence = data['valence'].values\n",
    "    return X, y_arousal, y_valence\n",
    "\n",
    "# Scale features (function)\n",
    "def scale_features(X_train, X_dev, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_dev_scaled = scaler.transform(X_dev)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
    "\n",
    "# SVR Grid Search (function)\n",
    "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
    "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
    "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
    "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model (function)\n",
    "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
    "    # Dev set\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
    "    rmse_dev = sqrt(mse_dev)\n",
    "    # Test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
    "\n",
    "# Paths to datasets\n",
    "train_file = \"2sec/SEWA_features_wav2vec_2_seconds_train.csv\"\n",
    "dev_file = \"2sec/SEWA_features_wav2vec_2_seconds_dev.csv\"\n",
    "test_file = \"2sec/SEWA_features_wav2vec_2_seconds_test.csv\"\n",
    "\n",
    "# Load and preprocess datasets\n",
    "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
    "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
    "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
    "\n",
    "# SVR parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Arousal Model\n",
    "best_svr_arousal = svr_grid_search(X_train_scaled, y_arousal_train, X_dev_scaled, y_arousal_dev, param_grid)\n",
    "mse_arousal_dev, rmse_arousal_dev, mse_arousal_test, rmse_arousal_test = evaluate_model(best_svr_arousal, X_dev_scaled, y_arousal_dev, X_test_scaled, y_arousal_test)\n",
    "\n",
    "# Valence Model\n",
    "best_svr_valence = svr_grid_search(X_train_scaled, y_valence_train, X_dev_scaled, y_valence_dev, param_grid)\n",
    "mse_valence_dev, rmse_valence_dev, mse_valence_test, rmse_valence_test = evaluate_model(best_svr_valence, X_dev_scaled, y_valence_dev, X_test_scaled, y_valence_test)\n",
    "\n",
    "# Results\n",
    "print(\"Arousal - Dev MSE:\", mse_arousal_dev, \"Dev RMSE:\", rmse_arousal_dev, \"Test MSE:\", mse_arousal_test, \"Test RMSE:\", rmse_arousal_test)\n",
    "print(\"Valence - Dev MSE:\", mse_valence_dev, \"Dev RMSE:\", rmse_valence_dev, \"Test MSE:\", mse_valence_test, \"Test RMSE:\", rmse_valence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1d40e-5f63-4b67-8613-580d07fa9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR 3 sec \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def load_and_preprocess_dataset(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    features_start_col = data.columns.get_loc(\"x_0\")\n",
    "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
    "    y_arousal = data['arousal'].values\n",
    "    y_valence = data['valence'].values\n",
    "    return X, y_arousal, y_valence\n",
    "\n",
    "# Scale features (function)\n",
    "def scale_features(X_train, X_dev, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_dev_scaled = scaler.transform(X_dev)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
    "\n",
    "# SVR Grid Search (function)\n",
    "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
    "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
    "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
    "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model (function)\n",
    "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
    "    # Dev set\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
    "    rmse_dev = sqrt(mse_dev)\n",
    "    # Test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
    "\n",
    "# Paths to datasets\n",
    "train_file = \"3sec/SEWA_features_wav2vec_3_seconds_train.csv\"\n",
    "dev_file = \"3sec/SEWA_features_wav2vec_3_seconds_dev.csv\"\n",
    "test_file = \"3sec/SEWA_features_wav2vec_3_seconds_test.csv\"\n",
    "\n",
    "# Load and preprocess datasets\n",
    "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
    "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
    "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
    "\n",
    "# SVR parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Arousal Model\n",
    "best_svr_arousal = svr_grid_search(X_train_scaled, y_arousal_train, X_dev_scaled, y_arousal_dev, param_grid)\n",
    "mse_arousal_dev, rmse_arousal_dev, mse_arousal_test, rmse_arousal_test = evaluate_model(best_svr_arousal, X_dev_scaled, y_arousal_dev, X_test_scaled, y_arousal_test)\n",
    "\n",
    "# Valence Model\n",
    "best_svr_valence = svr_grid_search(X_train_scaled, y_valence_train, X_dev_scaled, y_valence_dev, param_grid)\n",
    "mse_valence_dev, rmse_valence_dev, mse_valence_test, rmse_valence_test = evaluate_model(best_svr_valence, X_dev_scaled, y_valence_dev, X_test_scaled, y_valence_test)\n",
    "\n",
    "# Results\n",
    "print(\"Arousal - Dev MSE:\", mse_arousal_dev, \"Dev RMSE:\", rmse_arousal_dev, \"Test MSE:\", mse_arousal_test, \"Test RMSE:\", rmse_arousal_test)\n",
    "print(\"Valence - Dev MSE:\", mse_valence_dev, \"Dev RMSE:\", rmse_valence_dev, \"Test MSE:\", mse_valence_test, \"Test RMSE:\", rmse_valence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1bda9c-778c-4596-9ad7-a9417f4662fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR 4 sec \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def load_and_preprocess_dataset(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    features_start_col = data.columns.get_loc(\"x_0\")\n",
    "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
    "    y_arousal = data['arousal'].values\n",
    "    y_valence = data['valence'].values\n",
    "    return X, y_arousal, y_valence\n",
    "\n",
    "# Scale features (function)\n",
    "def scale_features(X_train, X_dev, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_dev_scaled = scaler.transform(X_dev)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
    "\n",
    "# SVR Grid Search (function)\n",
    "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
    "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
    "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
    "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
    "    pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model (function)\n",
    "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
    "    # Dev set\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
    "    rmse_dev = sqrt(mse_dev)\n",
    "    # Test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
    "\n",
    "# Paths to datasets\n",
    "train_file = \"4sec/SEWA_features_wav2vec_4_seconds_train.csv\"\n",
    "dev_file = \"4sec/SEWA_features_wav2vec_4_seconds_dev.csv\"\n",
    "test_file = \"4sec/SEWA_features_wav2vec_4_seconds_test.csv\"\n",
    "\n",
    "# Load and preprocess datasets\n",
    "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
    "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
    "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
    "\n",
    "# SVR parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Arousal Model\n",
    "best_svr_arousal = svr_grid_search(X_train_scaled, y_arousal_train, X_dev_scaled, y_arousal_dev, param_grid)\n",
    "mse_arousal_dev, rmse_arousal_dev, mse_arousal_test, rmse_arousal_test = evaluate_model(best_svr_arousal, X_dev_scaled, y_arousal_dev, X_test_scaled, y_arousal_test)\n",
    "\n",
    "# Valence Model\n",
    "best_svr_valence = svr_grid_search(X_train_scaled, y_valence_train, X_dev_scaled, y_valence_dev, param_grid)\n",
    "mse_valence_dev, rmse_valence_dev, mse_valence_test, rmse_valence_test = evaluate_model(best_svr_valence, X_dev_scaled, y_valence_dev, X_test_scaled, y_valence_test)\n",
    "\n",
    "# Results\n",
    "print(\"Arousal - Dev MSE:\", mse_arousal_dev, \"Dev RMSE:\", rmse_arousal_dev, \"Test MSE:\", mse_arousal_test, \"Test RMSE:\", rmse_arousal_test)\n",
    "print(\"Valence - Dev MSE:\", mse_valence_dev, \"Dev RMSE:\", rmse_valence_dev, \"Test MSE:\", mse_valence_test, \"Test RMSE:\", rmse_valence_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

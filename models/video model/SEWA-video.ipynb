{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b481cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home/kdatbayev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22416/1663326923.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
      "/home/kdatbayev/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.0197\n",
      "Epoch 1/10, Validation Loss: 0.0105\n",
      "Epoch 2/10, Training Loss: 0.0128\n",
      "Epoch 2/10, Validation Loss: 0.0100\n",
      "Epoch 3/10, Training Loss: 0.0118\n",
      "Epoch 3/10, Validation Loss: 0.0130\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 4/10, Training Loss: 0.0107\n",
      "Epoch 4/10, Validation Loss: 0.0108\n",
      "Epoch 5/10, Training Loss: 0.0102\n",
      "Epoch 5/10, Validation Loss: 0.0112\n",
      "Epoch 00009: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 6/10, Training Loss: 0.0096\n",
      "Epoch 6/10, Validation Loss: 0.0106\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 7/10, Training Loss: 0.0092\n",
      "Epoch 7/10, Validation Loss: 0.0105\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0840, Test RMSE Valence: 0.1251\n",
      "Test MAE Arousal: 0.0617, Test RMSE Arousal: 0.0779\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LSTM:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] / 10.\n",
    "        self.df['valence'] = self.df['valence'] / 10.\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[3:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "\n",
    "print(os.getcwd())\n",
    "# Load data\n",
    "train_df = pd.read_csv('AFEW-VA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('AFEW-VA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('AFEW-VA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 10\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of LSTM\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2 # Number of LSTM layers\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    "\n",
    "batch_size = 64 #before:32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# LSTM Network\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, bidirectional=True):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional #bidirectional lstm\n",
    "        #self.dropout = nn.Dropout(0.5) #add dropout before fully con.layer if overfitting\n",
    "\n",
    "\n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional) # GRU instead of LSTM\n",
    "\n",
    "\n",
    "        # Fully connected layer\n",
    "        # Multiply hidden_size by 2 if bidirectional\n",
    "        fc_input_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.fc = nn.Linear(fc_input_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #out = self.dropout(out)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.tanh(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = LSTMNetwork(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    #Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the model if desired\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "\n",
    "\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b60f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "  y_valence_true = []\n",
    "  y_valence_pred = []\n",
    "  y_arousal_true = []\n",
    "  y_arousal_pred = []\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "  # Calculate metrics\n",
    "  mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "  rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "  mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "  rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "  return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91326d8-9a40-463e-b740-5660ec0565ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (128x1x5). Calculated output size: (128x1x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 162\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    161\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 162\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    163\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    164\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 97\u001b[0m, in \u001b[0;36mGRUNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Apply 1D average pooling\u001b[39;00m\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Change shape to (batch_size, hidden_size, seq_length) for AvgPool1d\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_pool1d(out)\n\u001b[1;32m     98\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Remove the last dimension\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Decode the hidden state\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/nn/modules/pooling.py:555\u001b[0m, in \u001b[0;36mAvgPool1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mavg_pool1d(\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode,\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_include_pad)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (128x1x5). Calculated output size: (128x1x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "#GRU, AVG Pooling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] / 10.\n",
    "        self.df['valence'] = self.df['valence'] / 10.\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[3:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, seq_length=10, dropout_rate=0.5):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout_rate))\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # 1D Average Pooling\n",
    "        self.avg_pool1d = nn.AvgPool1d(seq_length)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Apply 1D average pooling\n",
    "        out = out.permute(0, 2, 1)  # Change shape to (batch_size, hidden_size, seq_length) for AvgPool1d\n",
    "        out = self.avg_pool1d(out)\n",
    "        out = out.squeeze(2)  # Remove the last dimension\n",
    "\n",
    "        # Decode the hidden state\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "# Hyperparameters\n",
    "window_size = 5\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of GRU layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32 #try 64 later\n",
    "epochs = 100\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('AFEW-VA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('AFEW-VA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('AFEW-VA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Custom RMSE Loss Function\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, predicted, actual):\n",
    "        return torch.sqrt(self.mse(predicted, actual))\n",
    "\n",
    "# Initialize the model with GRU\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers)\n",
    "#summary(model, (window_size, input_size))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "   \n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    #Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    # Save the model if desired\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Test evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fa328-4aac-4dc5-813f-cc79230e6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test test GRU avg pool old\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        # TODO: normalize arousal and valence\n",
    "        self.df['arousal'] = self.df['arousal'] / 10.\n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence'] / 10.\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[3:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('AFEW-VA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('AFEW-VA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('AFEW-VA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 15\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of LSTM\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.5):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.5)\n",
    "#summary(model, (window_size, input_size))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  # TODO: RMSE loss\n",
    "# criterion = nn.RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the model if desired\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402b472a-3ac0-44ce-a140-f474b8b1f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5994/270786724.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/tmp/ipykernel_5994/270786724.py:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343970094/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1013\n",
      "Epoch 1/100, Validation Loss: 0.0838\n",
      "Model saved to sewa-best_GRU_AVG-5.pth\n",
      "Epoch 2/100, Training Loss: 0.0869\n",
      "Epoch 2/100, Validation Loss: 0.0824\n",
      "Model saved to sewa-best_GRU_AVG-5.pth\n",
      "Epoch 3/100, Training Loss: 0.0852\n",
      "Epoch 3/100, Validation Loss: 0.0817\n",
      "Model saved to sewa-best_GRU_AVG-5.pth\n",
      "Epoch 4/100, Training Loss: 0.0834\n",
      "Epoch 4/100, Validation Loss: 0.0811\n",
      "Model saved to sewa-best_GRU_AVG-5.pth\n",
      "Epoch 5/100, Training Loss: 0.0837\n",
      "Epoch 5/100, Validation Loss: 0.0872\n",
      "Epoch 6/100, Training Loss: 0.0830\n",
      "Epoch 6/100, Validation Loss: 0.0861\n",
      "Epoch 7/100, Training Loss: 0.0821\n",
      "Epoch 7/100, Validation Loss: 0.0816\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 8/100, Training Loss: 0.0778\n",
      "Epoch 8/100, Validation Loss: 0.0804\n",
      "Model saved to sewa-best_GRU_AVG-5.pth\n",
      "Epoch 9/100, Training Loss: 0.0763\n",
      "Epoch 9/100, Validation Loss: 0.0801\n",
      "Model saved to sewa-best_GRU_AVG-5.pth\n",
      "Epoch 10/100, Training Loss: 0.0759\n",
      "Epoch 10/100, Validation Loss: 0.0801\n",
      "Epoch 11/100, Training Loss: 0.0757\n",
      "Epoch 11/100, Validation Loss: 0.0801\n",
      "Epoch 12/100, Training Loss: 0.0749\n",
      "Epoch 12/100, Validation Loss: 0.0815\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 13/100, Training Loss: 0.0743\n",
      "Epoch 13/100, Validation Loss: 0.0809\n",
      "Epoch 14/100, Training Loss: 0.0746\n",
      "Epoch 14/100, Validation Loss: 0.0807\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0893, Test RMSE Valence: 0.1141\n",
      "Test MAE Arousal: 0.0955, Test RMSE Arousal: 0.1225\n"
     ]
    }
   ],
   "source": [
    "#GRU avg pool WITH GPU CPU SWITCH, sewa 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 5\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.5):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Directly average across the sequence length dimension\n",
    "        out = torch.mean(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_AVG-5.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2162caa-b0ba-40f9-bde0-e911e557c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1177\n",
      "Epoch 1/100, Validation Loss: 0.0799\n",
      "Model saved to sewa-best_GRU_AVG-10.pth\n",
      "Epoch 2/100, Training Loss: 0.0790\n",
      "Epoch 2/100, Validation Loss: 0.0737\n",
      "Model saved to sewa-best_GRU_AVG-10.pth\n",
      "Epoch 3/100, Training Loss: 0.0765\n",
      "Epoch 3/100, Validation Loss: 0.0740\n",
      "Epoch 4/100, Training Loss: 0.0771\n",
      "Epoch 4/100, Validation Loss: 0.0752\n",
      "Epoch 5/100, Training Loss: 0.0761\n",
      "Epoch 5/100, Validation Loss: 0.0767\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 6/100, Training Loss: 0.0705\n",
      "Epoch 6/100, Validation Loss: 0.0738\n",
      "Epoch 7/100, Training Loss: 0.0688\n",
      "Epoch 7/100, Validation Loss: 0.0748\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0850, Test RMSE Valence: 0.1077\n",
      "Test MAE Arousal: 0.0894, Test RMSE Arousal: 0.1159\n"
     ]
    }
   ],
   "source": [
    "#GRU avg pool WITH GPU CPU SWITCH, sewa 10 //TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 10\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Directly average across the sequence length dimension\n",
    "        out = torch.mean(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_AVG-10.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db14521-7e16-4759-9424-7e1eab14eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1270\n",
      "Epoch 1/100, Validation Loss: 0.0930\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 2/100, Training Loss: 0.0762\n",
      "Epoch 2/100, Validation Loss: 0.0762\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 3/100, Training Loss: 0.0749\n",
      "Epoch 3/100, Validation Loss: 0.0756\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 4/100, Training Loss: 0.0727\n",
      "Epoch 4/100, Validation Loss: 0.0726\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 5/100, Training Loss: 0.0725\n",
      "Epoch 5/100, Validation Loss: 0.0803\n",
      "Epoch 6/100, Training Loss: 0.0720\n",
      "Epoch 6/100, Validation Loss: 0.0720\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 7/100, Training Loss: 0.0698\n",
      "Epoch 7/100, Validation Loss: 0.0763\n",
      "Epoch 8/100, Training Loss: 0.0707\n",
      "Epoch 8/100, Validation Loss: 0.0761\n",
      "Epoch 9/100, Training Loss: 0.0697\n",
      "Epoch 9/100, Validation Loss: 0.0772\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 10/100, Training Loss: 0.0655\n",
      "Epoch 10/100, Validation Loss: 0.0713\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 11/100, Training Loss: 0.0636\n",
      "Epoch 11/100, Validation Loss: 0.0728\n",
      "Epoch 12/100, Training Loss: 0.0626\n",
      "Epoch 12/100, Validation Loss: 0.0706\n",
      "Model saved to sewa-best_GRU_AVG-15.pth\n",
      "Epoch 13/100, Training Loss: 0.0618\n",
      "Epoch 13/100, Validation Loss: 0.0717\n",
      "Epoch 14/100, Training Loss: 0.0614\n",
      "Epoch 14/100, Validation Loss: 0.0725\n",
      "Epoch 15/100, Training Loss: 0.0613\n",
      "Epoch 15/100, Validation Loss: 0.0721\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 16/100, Training Loss: 0.0602\n",
      "Epoch 16/100, Validation Loss: 0.0718\n",
      "Epoch 17/100, Training Loss: 0.0601\n",
      "Epoch 17/100, Validation Loss: 0.0725\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0793, Test RMSE Valence: 0.1029\n",
      "Test MAE Arousal: 0.0848, Test RMSE Arousal: 0.1106\n"
     ]
    }
   ],
   "source": [
    "#GRU avg pool WITH GPU CPU SWITCH, sewa 15 //TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 15\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Directly average across the sequence length dimension\n",
    "        out = torch.mean(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_AVG-15.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8156a9ae-f94e-4d28-be97-8e49eaef7815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1065\n",
      "Epoch 1/100, Validation Loss: 0.0686\n",
      "Model saved to sewa-best_GRU_AVG-20.pth\n",
      "Epoch 2/100, Training Loss: 0.0711\n",
      "Epoch 2/100, Validation Loss: 0.0740\n",
      "Epoch 3/100, Training Loss: 0.0689\n",
      "Epoch 3/100, Validation Loss: 0.0693\n",
      "Epoch 4/100, Training Loss: 0.0655\n",
      "Epoch 4/100, Validation Loss: 0.0706\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 5/100, Training Loss: 0.0606\n",
      "Epoch 5/100, Validation Loss: 0.0689\n",
      "Epoch 6/100, Training Loss: 0.0588\n",
      "Epoch 6/100, Validation Loss: 0.0688\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0805, Test RMSE Valence: 0.1050\n",
      "Test MAE Arousal: 0.0887, Test RMSE Arousal: 0.1135\n"
     ]
    }
   ],
   "source": [
    "#GRU avg pool WITH GPU CPU SWITCH, sewa 20 //TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 20\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Directly average across the sequence length dimension\n",
    "        out = torch.mean(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_AVG-20.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91082152-d545-40a2-912a-4dd8837671ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1131\n",
      "Epoch 1/100, Validation Loss: 0.0842\n",
      "Model saved to sewa-best_GRU_MAX-5.pth\n",
      "Epoch 2/100, Training Loss: 0.0856\n",
      "Epoch 2/100, Validation Loss: 0.0852\n",
      "Epoch 3/100, Training Loss: 0.0849\n",
      "Epoch 3/100, Validation Loss: 0.0806\n",
      "Model saved to sewa-best_GRU_MAX-5.pth\n",
      "Epoch 4/100, Training Loss: 0.0843\n",
      "Epoch 4/100, Validation Loss: 0.0809\n",
      "Epoch 5/100, Training Loss: 0.0830\n",
      "Epoch 5/100, Validation Loss: 0.0798\n",
      "Model saved to sewa-best_GRU_MAX-5.pth\n",
      "Epoch 6/100, Training Loss: 0.0828\n",
      "Epoch 6/100, Validation Loss: 0.0807\n",
      "Epoch 7/100, Training Loss: 0.0816\n",
      "Epoch 7/100, Validation Loss: 0.0801\n",
      "Epoch 8/100, Training Loss: 0.0815\n",
      "Epoch 8/100, Validation Loss: 0.0781\n",
      "Model saved to sewa-best_GRU_MAX-5.pth\n",
      "Epoch 9/100, Training Loss: 0.0827\n",
      "Epoch 9/100, Validation Loss: 0.0850\n",
      "Epoch 10/100, Training Loss: 0.0812\n",
      "Epoch 10/100, Validation Loss: 0.0825\n",
      "Epoch 11/100, Training Loss: 0.0801\n",
      "Epoch 11/100, Validation Loss: 0.0801\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 12/100, Training Loss: 0.0761\n",
      "Epoch 12/100, Validation Loss: 0.0796\n",
      "Epoch 13/100, Training Loss: 0.0751\n",
      "Epoch 13/100, Validation Loss: 0.0802\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0995, Test RMSE Valence: 0.1288\n",
      "Test MAE Arousal: 0.0945, Test RMSE Arousal: 0.1226\n"
     ]
    }
   ],
   "source": [
    "#GRU max pool with GPU SWITCH, sewa 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 5\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.5):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # torch.max returns both the max values and the indices, so we select the values with [0]\n",
    "        out, _ = torch.max(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_MAX-5.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move inputs, labels to the same device as the model\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5649652-6c8e-43f7-9046-acf9c46fdfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1013\n",
      "Epoch 1/100, Validation Loss: 0.0789\n",
      "Model saved to sewa-best_GRU_MAX-10.pth\n",
      "Epoch 2/100, Training Loss: 0.0827\n",
      "Epoch 2/100, Validation Loss: 0.0776\n",
      "Model saved to sewa-best_GRU_MAX-10.pth\n",
      "Epoch 3/100, Training Loss: 0.0796\n",
      "Epoch 3/100, Validation Loss: 0.0798\n",
      "Epoch 4/100, Training Loss: 0.0789\n",
      "Epoch 4/100, Validation Loss: 0.0831\n",
      "Epoch 5/100, Training Loss: 0.0769\n",
      "Epoch 5/100, Validation Loss: 0.0838\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 6/100, Training Loss: 0.0716\n",
      "Epoch 6/100, Validation Loss: 0.0737\n",
      "Model saved to sewa-best_GRU_MAX-10.pth\n",
      "Epoch 7/100, Training Loss: 0.0699\n",
      "Epoch 7/100, Validation Loss: 0.0766\n",
      "Epoch 8/100, Training Loss: 0.0696\n",
      "Epoch 8/100, Validation Loss: 0.0761\n",
      "Epoch 9/100, Training Loss: 0.0689\n",
      "Epoch 9/100, Validation Loss: 0.0751\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 10/100, Training Loss: 0.0679\n",
      "Epoch 10/100, Validation Loss: 0.0750\n",
      "Epoch 11/100, Training Loss: 0.0680\n",
      "Epoch 11/100, Validation Loss: 0.0750\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0888, Test RMSE Valence: 0.1171\n",
      "Test MAE Arousal: 0.0901, Test RMSE Arousal: 0.1155\n"
     ]
    }
   ],
   "source": [
    "#GRU max pool with GPU SWITCH, sewa 10  //TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 10\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.5):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # torch.max returns both the max values and the indices, so we select the values with [0]\n",
    "        out, _ = torch.max(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_MAX-10.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move inputs, labels to the same device as the model\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac27f98a-29e7-465c-bbbe-67442717300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1076\n",
      "Epoch 1/100, Validation Loss: 0.0786\n",
      "Model saved to sewa-best_GRU_MAX-15.pth\n",
      "Epoch 2/100, Training Loss: 0.0773\n",
      "Epoch 2/100, Validation Loss: 0.0804\n",
      "Epoch 3/100, Training Loss: 0.0752\n",
      "Epoch 3/100, Validation Loss: 0.0795\n",
      "Epoch 4/100, Training Loss: 0.0724\n",
      "Epoch 4/100, Validation Loss: 0.0755\n",
      "Model saved to sewa-best_GRU_MAX-15.pth\n",
      "Epoch 5/100, Training Loss: 0.0727\n",
      "Epoch 5/100, Validation Loss: 0.0747\n",
      "Model saved to sewa-best_GRU_MAX-15.pth\n",
      "Epoch 6/100, Training Loss: 0.0711\n",
      "Epoch 6/100, Validation Loss: 0.0721\n",
      "Model saved to sewa-best_GRU_MAX-15.pth\n",
      "Epoch 7/100, Training Loss: 0.0703\n",
      "Epoch 7/100, Validation Loss: 0.0780\n",
      "Epoch 8/100, Training Loss: 0.0700\n",
      "Epoch 8/100, Validation Loss: 0.0715\n",
      "Model saved to sewa-best_GRU_MAX-15.pth\n",
      "Epoch 9/100, Training Loss: 0.0697\n",
      "Epoch 9/100, Validation Loss: 0.0814\n",
      "Epoch 10/100, Training Loss: 0.0700\n",
      "Epoch 10/100, Validation Loss: 0.0735\n",
      "Epoch 11/100, Training Loss: 0.0694\n",
      "Epoch 11/100, Validation Loss: 0.0787\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 12/100, Training Loss: 0.0642\n",
      "Epoch 12/100, Validation Loss: 0.0727\n",
      "Epoch 13/100, Training Loss: 0.0625\n",
      "Epoch 13/100, Validation Loss: 0.0731\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0839, Test RMSE Valence: 0.1107\n",
      "Test MAE Arousal: 0.0894, Test RMSE Arousal: 0.1135\n"
     ]
    }
   ],
   "source": [
    "#GRU max pool with GPU SWITCH, sewa 15  //TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 15\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.5):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # torch.max returns both the max values and the indices, so we select the values with [0]\n",
    "        out, _ = torch.max(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_MAX-15.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move inputs, labels to the same device as the model\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path)) \n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64416cbd-40fe-44bd-aea4-756bc01ef983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.1019\n",
      "Epoch 1/100, Validation Loss: 0.0879\n",
      "Model saved to sewa-best_GRU_MAX-20.pth\n",
      "Epoch 2/100, Training Loss: 0.0755\n",
      "Epoch 2/100, Validation Loss: 0.0736\n",
      "Model saved to sewa-best_GRU_MAX-20.pth\n",
      "Epoch 3/100, Training Loss: 0.0738\n",
      "Epoch 3/100, Validation Loss: 0.0889\n",
      "Epoch 4/100, Training Loss: 0.0703\n",
      "Epoch 4/100, Validation Loss: 0.0690\n",
      "Model saved to sewa-best_GRU_MAX-20.pth\n",
      "Epoch 5/100, Training Loss: 0.0709\n",
      "Epoch 5/100, Validation Loss: 0.0696\n",
      "Epoch 6/100, Training Loss: 0.0684\n",
      "Epoch 6/100, Validation Loss: 0.0683\n",
      "Model saved to sewa-best_GRU_MAX-20.pth\n",
      "Epoch 7/100, Training Loss: 0.0679\n",
      "Epoch 7/100, Validation Loss: 0.0699\n",
      "Epoch 8/100, Training Loss: 0.0667\n",
      "Epoch 8/100, Validation Loss: 0.0814\n",
      "Epoch 9/100, Training Loss: 0.0663\n",
      "Epoch 9/100, Validation Loss: 0.0699\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 10/100, Training Loss: 0.0599\n",
      "Epoch 10/100, Validation Loss: 0.0692\n",
      "Epoch 11/100, Training Loss: 0.0584\n",
      "Epoch 11/100, Validation Loss: 0.0700\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.0990, Test RMSE Valence: 0.1273\n",
      "Test MAE Arousal: 0.0884, Test RMSE Arousal: 0.1138\n"
     ]
    }
   ],
   "source": [
    "#GRU max pool with GPU SWITCH, sewa 20  //TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU before converting to numpy\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 20\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # torch.max returns both the max values and the indices, so we select the values with [0]\n",
    "        out, _ = torch.max(out, dim=1)\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_MAX-20.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move inputs, labels to the same device as the model\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa105122-738e-4ee5-9499-18cce968edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9138\n",
      "Epoch 1/100, Validation Loss: 0.9016\n",
      "Model saved to sewa-best_GRU_1D-5.pth\n",
      "Epoch 2/100, Training Loss: 0.9102\n",
      "Epoch 2/100, Validation Loss: 0.9014\n",
      "Model saved to sewa-best_GRU_1D-5.pth\n",
      "Epoch 3/100, Training Loss: 0.9102\n",
      "Epoch 3/100, Validation Loss: 0.9014\n",
      "Epoch 4/100, Training Loss: 0.9102\n",
      "Epoch 4/100, Validation Loss: 0.9014\n",
      "Epoch 5/100, Training Loss: 0.9102\n",
      "Epoch 5/100, Validation Loss: 0.9014\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 6/100, Training Loss: 0.9102\n",
      "Epoch 6/100, Validation Loss: 0.9014\n",
      "Epoch 7/100, Training Loss: 0.9103\n",
      "Epoch 7/100, Validation Loss: 0.9014\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.9532, Test RMSE Valence: 0.9682\n",
      "Test MAE Arousal: 0.9539, Test RMSE Arousal: 0.9673\n"
     ]
    }
   ],
   "source": [
    "#GRU 1d cnn SEWA 5 DONE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 5\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2, cnn_kernel_size=window_size, cnn_out_channels=hidden_size):\n",
    "        #cnn kernel size = window size\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # 1D CNN Layer for local feature extraction\n",
    "        # Adjust in_channels to match the GRU's output hidden size\n",
    "        # You can choose cnn_out_channels to transform feature dimensionality if desired\n",
    "        self.conv1d_layer = nn.Conv1d(in_channels=hidden_size, out_channels=cnn_out_channels, kernel_size=cnn_kernel_size)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(cnn_out_channels, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Apply 1D CNN\n",
    "        out = out.permute(0, 2, 1)  # Permute for Conv1d\n",
    "        out = self.conv1d_layer(out)\n",
    "        out = out.squeeze()  # Squeeze the singleton dimension/ should be 128,    ?  \n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")      \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_1D-5.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af2a828-0c7f-45f7-8fb2-21ff4216d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.0228\n",
      "Epoch 1/100, Validation Loss: 1.0249\n",
      "Model saved to sewa-best_GRU_1D-10.pth\n",
      "Epoch 2/100, Training Loss: 1.0280\n",
      "Epoch 2/100, Validation Loss: 1.0249\n",
      "Epoch 3/100, Training Loss: 1.0280\n",
      "Epoch 3/100, Validation Loss: 1.0249\n",
      "Epoch 4/100, Training Loss: 1.0280\n",
      "Epoch 4/100, Validation Loss: 1.0249\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 5/100, Training Loss: 1.0280\n",
      "Epoch 5/100, Validation Loss: 1.0249\n",
      "Epoch 6/100, Training Loss: 1.0280\n",
      "Epoch 6/100, Validation Loss: 1.0249\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 1.0467, Test RMSE Valence: 1.0599\n",
      "Test MAE Arousal: 0.9539, Test RMSE Arousal: 0.9669\n"
     ]
    }
   ],
   "source": [
    "#GRU 1d cnn SEWA 10 TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 10\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2, cnn_kernel_size=window_size, cnn_out_channels=hidden_size):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # 1D CNN Layer for local feature extraction\n",
    "        # Adjust in_channels to match the GRU's output hidden size\n",
    "        # You can choose cnn_out_channels to transform feature dimensionality if desired\n",
    "        self.conv1d_layer = nn.Conv1d(in_channels=hidden_size, out_channels=cnn_out_channels, kernel_size=cnn_kernel_size)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(cnn_out_channels, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Apply 1D CNN\n",
    "        out = out.permute(0, 2, 1)  # Permute for Conv1d\n",
    "        out = self.conv1d_layer(out)\n",
    "        out = out.squeeze()  # Squeeze the singleton dimension\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")      \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_1D-10.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0afcae26-d7d5-430f-bab2-83b8ba09c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.0954\n",
      "Epoch 1/100, Validation Loss: 1.1094\n",
      "Model saved to sewa-best_GRU_1D-15.pth\n",
      "Epoch 2/100, Training Loss: 1.1063\n",
      "Epoch 2/100, Validation Loss: 1.1094\n",
      "Epoch 3/100, Training Loss: 1.1062\n",
      "Epoch 3/100, Validation Loss: 1.1094\n",
      "Epoch 4/100, Training Loss: 1.1063\n",
      "Epoch 4/100, Validation Loss: 1.1094\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 5/100, Training Loss: 1.1062\n",
      "Epoch 5/100, Validation Loss: 1.1094\n",
      "Epoch 6/100, Training Loss: 1.1062\n",
      "Epoch 6/100, Validation Loss: 1.1094\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 1.0466, Test RMSE Valence: 1.0594\n",
      "Test MAE Arousal: 1.0457, Test RMSE Arousal: 1.0572\n"
     ]
    }
   ],
   "source": [
    "#GRU 1d cnn SEWA 15 TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 15\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2, cnn_kernel_size=window_size, cnn_out_channels=hidden_size):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # 1D CNN Layer for local feature extraction\n",
    "        # Adjust in_channels to match the GRU's output hidden size\n",
    "        # You can choose cnn_out_channels to transform feature dimensionality if desired\n",
    "        self.conv1d_layer = nn.Conv1d(in_channels=hidden_size, out_channels=cnn_out_channels, kernel_size=cnn_kernel_size)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(cnn_out_channels, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Apply 1D CNN\n",
    "        out = out.permute(0, 2, 1)  # Permute for Conv1d\n",
    "        out = self.conv1d_layer(out)\n",
    "        out = out.squeeze()  # Squeeze the singleton dimension\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")      \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_1D-15.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c994b9f3-60f2-4555-8a87-6e014d0faf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9041\n",
      "Epoch 1/100, Validation Loss: 0.9003\n",
      "Model saved to sewa-best_GRU_1D-20.pth\n",
      "Epoch 2/100, Training Loss: 0.9085\n",
      "Epoch 2/100, Validation Loss: 0.9003\n",
      "Epoch 3/100, Training Loss: 0.9085\n",
      "Epoch 3/100, Validation Loss: 0.9003\n",
      "Epoch 4/100, Training Loss: 0.9085\n",
      "Epoch 4/100, Validation Loss: 0.9003\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 5/100, Training Loss: 0.9084\n",
      "Epoch 5/100, Validation Loss: 0.9003\n",
      "Epoch 6/100, Training Loss: 0.9085\n",
      "Epoch 6/100, Validation Loss: 0.9003\n",
      "Early stopping triggered\n",
      "Test MAE Valence: 0.9533, Test RMSE Valence: 0.9670\n",
      "Test MAE Arousal: 0.9539, Test RMSE Arousal: 0.9660\n"
     ]
    }
   ],
   "source": [
    "#GRU 1d cnn SEWA 20 TODO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from torchsummary import summary\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move inputs to GPU\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to('cpu')  # Move outputs back to CPU\n",
    "\n",
    "            # Ensure labels are on CPU before converting to numpy\n",
    "            labels = labels.to('cpu')\n",
    "            \n",
    "            y_true.append(labels.numpy())\n",
    "            y_pred.append(outputs.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
    "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
    "\n",
    "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
    "\n",
    "\n",
    "def predict_on_dev(model, dev_loader):\n",
    "    y_valence_true = []\n",
    "    y_valence_pred = []\n",
    "    y_arousal_true = []\n",
    "    y_arousal_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dev_loader:\n",
    "          # Send inputs and labels to GPU\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "          labels_valence = labels[:, 0]\n",
    "          labels_arousal = labels[:, 1]\n",
    "          outputs_valence = outputs[:, 0]\n",
    "          outputs_arousal = outputs[:, 1]\n",
    "\n",
    "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
    "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
    "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
    "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
    "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
    "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
    "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
    "\n",
    "    return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomVideoDataset(Dataset):\n",
    "    def __init__(self, df, window_size=10, stride=5):\n",
    "        self.df = df\n",
    "        self.df['arousal'] = self.df['arousal'] \n",
    "        #print(df)\n",
    "        self.df['valence'] = self.df['valence']\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_frames = self.video_windows[idx]\n",
    "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[4:]].values for frame in window_frames]\n",
    "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
    "\n",
    "        labels = self.labels_windows[idx]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "    def prepare_windows(self):\n",
    "        video_frames = {}\n",
    "        labels = {}\n",
    "        for _, row in self.df.iterrows():\n",
    "            video_id = self.extract_video_info(row['path'])\n",
    "            if video_id not in video_frames:\n",
    "                video_frames[video_id] = []\n",
    "                labels[video_id] = []\n",
    "            video_frames[video_id].append(row['path'])\n",
    "            labels[video_id].append((row['arousal'], row['valence']))\n",
    "\n",
    "        video_windows = []\n",
    "        labels_windows = []\n",
    "        for video_id in video_frames:\n",
    "            frames = video_frames[video_id]\n",
    "            label_vals = labels[video_id]\n",
    "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
    "                video_windows.append(frames[i:i + self.window_size])\n",
    "                window_labels = label_vals[i:i + self.window_size]\n",
    "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
    "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
    "                labels_windows.append((avg_arousal, avg_valence))\n",
    "\n",
    "        return video_windows, labels_windows\n",
    "\n",
    "    def extract_video_info(self, file_path):\n",
    "        parts = file_path.split('/')\n",
    "        video_id = parts[-2]\n",
    "        return video_id\n",
    "        \n",
    "# RMSELoss as a class\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "        \n",
    "# Load data\n",
    "train_df = pd.read_csv('SEWA_radiant_fog_160_train.csv')\n",
    "dev_df = pd.read_csv('SEWA_radiant_fog_160_dev.csv')\n",
    "test_df = pd.read_csv('SEWA_radiant_fog_160_test.csv')\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 20\n",
    "input_size = 256  # Number of features (embeddings) per frame\n",
    "hidden_size = 128  # Number of features in hidden state of GRU\n",
    "output_size = 2  # Output size (arousal and valence)\n",
    "num_layers = 2  # Number of layers\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomVideoDataset(train_df, window_size)\n",
    "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
    "test_dataset = CustomVideoDataset(test_df, window_size)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# GRU Network\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2, cnn_kernel_size=window_size, cnn_out_channels=hidden_size):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # 1D CNN Layer for local feature extraction\n",
    "        # Adjust in_channels to match the GRU's output hidden size\n",
    "        # You can choose cnn_out_channels to transform feature dimensionality if desired\n",
    "        self.conv1d_layer = nn.Conv1d(in_channels=hidden_size, out_channels=cnn_out_channels, kernel_size=cnn_kernel_size)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(cnn_out_channels, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout layer applied to the output of the GRU layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Apply 1D CNN\n",
    "        out = out.permute(0, 2, 1)  # Permute for Conv1d\n",
    "        out = self.conv1d_layer(out)\n",
    "        out = out.squeeze()  # Squeeze the singleton dimension\n",
    "        \n",
    "        # Apply dropout to the outputs of the GRU layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Decode the averaged output\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")      \n",
    "# Initialize the model, optimizer, and RMSELoss\n",
    "model = GRUNetwork(input_size, hidden_size, output_size, num_layers, dropout_rate=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = RMSELoss() \n",
    "\n",
    "# adding learning rate scheduler to dynamically adjust the LR\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "model_save_path = 'sewa-best_GRU_1D-20.pth'  # Define model save path \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in dev_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(dev_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
    "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
    "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2wqz0mWc2Dg",
        "outputId": "aaff2208-4c52-4996-e3e6-fffc2a76eb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 SEC done\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Function to load and preprocess audio dataset\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values # Adjusted to slice till the end\n",
        "    y = data[[\"valence\", \"arousal\"]].values\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# Define a fully connected neural network for regression\n",
        "class FullyConnectedNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FullyConnectedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "# RMSE Loss Function\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        return torch.sqrt(self.mse(yhat, y))\n",
        "\n",
        "# Function to predict on dev set\n",
        "def predict_on_dev(model, dev_loader):\n",
        "    y_valence_true, y_valence_pred = [], []\n",
        "    y_arousal_true, y_arousal_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dev_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence, labels_arousal = labels[:, 0], labels[:, 1]\n",
        "            outputs_valence, outputs_arousal = outputs[:, 0], outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
        "\n",
        "train_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_test.csv\"\n",
        "\n",
        "# Load and preprocess datasets\n",
        "X_train, y_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(TensorDataset(X_dev, y_dev), batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Neural Network Hyperparameters\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Model, Loss Function, and Optimizer\n",
        "model = FullyConnectedNN(input_dim, hidden_dim, output_dim)\n",
        "criterion_arousal = RMSELoss()\n",
        "criterion_valence = RMSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Instantiate the scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7, verbose=True)\n",
        "\n",
        "# Initialize early stopping parameters\n",
        "patience = 10\n",
        "min_val_loss = float('inf')\n",
        "counter = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss_arousal = criterion_arousal(outputs[:, 0], labels[:, 0])\n",
        "        loss_valence = criterion_valence(outputs[:, 1], labels[:, 1])\n",
        "        loss = loss_arousal + loss_valence\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    val_mae_valence, val_rmse_valence, val_mae_arousal, val_rmse_arousal = predict_on_dev(model, dev_loader)\n",
        "\n",
        "    # Early stopping checks\n",
        "    val_loss = (val_rmse_valence + val_rmse_arousal) / 2\n",
        "    print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}')\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        counter = 0\n",
        "        best_epoch = epoch\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), 'best_model_audio-ONE-SEC.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "print(f\"Training stopped after {best_epoch+1} epochs\")\n",
        "\n",
        "def evaluate_on_test(model, test_loader):\n",
        "    y_valence_true = []\n",
        "    y_valence_pred = []\n",
        "    y_arousal_true = []\n",
        "    y_arousal_pred = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence = labels[:, 0]\n",
        "            labels_arousal = labels[:, 1]\n",
        "            outputs_valence = outputs[:, 0]\n",
        "            outputs_arousal = outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    print(f\"Test MAE Valence: {mae_valence:.4f}, RMSE Valence: {rmse_valence:.4f}\")\n",
        "    print(f\"Test MAE Arousal: {mae_arousal:.4f}, RMSE Arousal: {rmse_arousal:.4f}\")\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model_audio-ONE-SEC.pth'))\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "evaluate_on_test(model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFGcgfSDfbfK",
        "outputId": "12a7d6ac-6b42-4fc8-96a8-06d11f68b989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.1266\n",
            "Epoch 2, Val Loss: 0.1270\n",
            "Epoch 3, Val Loss: 0.1267\n",
            "Epoch 4, Val Loss: 0.1267\n",
            "Epoch 5, Val Loss: 0.1258\n",
            "Epoch 6, Val Loss: 0.1260\n",
            "Epoch 7, Val Loss: 0.1265\n",
            "Epoch 8, Val Loss: 0.1253\n",
            "Epoch 9, Val Loss: 0.1251\n",
            "Epoch 10, Val Loss: 0.1285\n",
            "Epoch 11, Val Loss: 0.1255\n",
            "Epoch 12, Val Loss: 0.1279\n",
            "Epoch 13, Val Loss: 0.1276\n",
            "Epoch 14, Val Loss: 0.1271\n",
            "Epoch 15, Val Loss: 0.1254\n",
            "Epoch 16, Val Loss: 0.1256\n",
            "Epoch 17, Val Loss: 0.1254\n",
            "Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 18, Val Loss: 0.1252\n",
            "Epoch 19, Val Loss: 0.1255\n",
            "Early stopping triggered\n",
            "Training stopped after 9 epochs\n",
            "Test MAE Valence: 0.1326, RMSE Valence: 0.1669\n",
            "Test MAE Arousal: 0.1339, RMSE Arousal: 0.1796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = load_and_preprocess_dataset(train_file)\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuwDD5sbgVD5",
        "outputId": "b00d3513-f813-48ff-9a26-8fa558d6bfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([9478, 768]), y_train shape: torch.Size([9478, 2])\n",
            "tensor([[-0.0729,  0.0021,  0.1717,  ..., -0.1230, -0.0004, -0.1102],\n",
            "        [-0.0766,  0.0117,  0.0313,  ...,  0.0146, -0.0082, -0.0802],\n",
            "        [-0.0092,  0.0022, -0.0328,  ..., -0.1054, -0.0195, -0.0545],\n",
            "        ...,\n",
            "        [-0.2134,  0.0506,  0.0328,  ...,  0.0360,  0.0300, -0.0583],\n",
            "        [-0.2995,  0.0570,  0.1754,  ..., -0.0725,  0.0316, -0.0728],\n",
            "        [-0.0641, -0.0285,  0.0678,  ..., -0.0521, -0.0176, -0.1609]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 SEC done\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Function to load and preprocess audio dataset\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values # Adjusted to slice till the end\n",
        "    y = data[[\"valence\", \"arousal\"]].values\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# Define a fully connected neural network for regression\n",
        "class FullyConnectedNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FullyConnectedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "# RMSE Loss Function\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        return torch.sqrt(self.mse(yhat, y))\n",
        "\n",
        "# Function to predict on dev set\n",
        "def predict_on_dev(model, dev_loader):\n",
        "    y_valence_true, y_valence_pred = [], []\n",
        "    y_arousal_true, y_arousal_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dev_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence, labels_arousal = labels[:, 0], labels[:, 1]\n",
        "            outputs_valence, outputs_arousal = outputs[:, 0], outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
        "\n",
        "train_file = \"/content/drive/MyDrive/2sec/SEWA_features_wav2vec_2_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/2sec/SEWA_features_wav2vec_2_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/2sec/SEWA_features_wav2vec_2_seconds_test.csv\"\n",
        "\n",
        "# Load and preprocess datasets\n",
        "X_train, y_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(TensorDataset(X_dev, y_dev), batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Neural Network Hyperparameters\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Model, Loss Function, and Optimizer\n",
        "model = FullyConnectedNN(input_dim, hidden_dim, output_dim)\n",
        "criterion_arousal = RMSELoss()\n",
        "criterion_valence = RMSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Instantiate the scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7, verbose=True)\n",
        "\n",
        "# Initialize early stopping parameters\n",
        "patience = 10\n",
        "min_val_loss = float('inf')\n",
        "counter = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss_arousal = criterion_arousal(outputs[:, 0], labels[:, 0])\n",
        "        loss_valence = criterion_valence(outputs[:, 1], labels[:, 1])\n",
        "        loss = loss_arousal + loss_valence\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    val_mae_valence, val_rmse_valence, val_mae_arousal, val_rmse_arousal = predict_on_dev(model, dev_loader)\n",
        "\n",
        "    # Early stopping checks\n",
        "    val_loss = (val_rmse_valence + val_rmse_arousal) / 2\n",
        "    print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        counter = 0\n",
        "        best_epoch = epoch\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), 'best_model_audio-TWO-SEC.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "print(f\"Training stopped after {best_epoch+1} epochs\")\n",
        "\n",
        "def evaluate_on_test(model, test_loader):\n",
        "    y_valence_true = []\n",
        "    y_valence_pred = []\n",
        "    y_arousal_true = []\n",
        "    y_arousal_pred = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence = labels[:, 0]\n",
        "            labels_arousal = labels[:, 1]\n",
        "            outputs_valence = outputs[:, 0]\n",
        "            outputs_arousal = outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    print(f\"Test MAE Valence: {mae_valence:.4f}, RMSE Valence: {rmse_valence:.4f}\")\n",
        "    print(f\"Test MAE Arousal: {mae_arousal:.4f}, RMSE Arousal: {rmse_arousal:.4f}\")\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model_audio-TWO-SEC.pth'))\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "evaluate_on_test(model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSzI-bMNkTbx",
        "outputId": "c945a835-0c6a-4656-de65-9efd6c46a144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.1258\n",
            "Epoch 2, Val Loss: 0.1277\n",
            "Epoch 3, Val Loss: 0.1261\n",
            "Epoch 4, Val Loss: 0.1252\n",
            "Epoch 5, Val Loss: 0.1254\n",
            "Epoch 6, Val Loss: 0.1264\n",
            "Epoch 7, Val Loss: 0.1257\n",
            "Epoch 8, Val Loss: 0.1262\n",
            "Epoch 9, Val Loss: 0.1248\n",
            "Epoch 10, Val Loss: 0.1252\n",
            "Epoch 11, Val Loss: 0.1250\n",
            "Epoch 12, Val Loss: 0.1252\n",
            "Epoch 13, Val Loss: 0.1265\n",
            "Epoch 14, Val Loss: 0.1271\n",
            "Epoch 15, Val Loss: 0.1260\n",
            "Epoch 16, Val Loss: 0.1263\n",
            "Epoch 17, Val Loss: 0.1273\n",
            "Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 18, Val Loss: 0.1252\n",
            "Epoch 19, Val Loss: 0.1249\n",
            "Early stopping triggered\n",
            "Training stopped after 9 epochs\n",
            "Test MAE Valence: 0.1347, RMSE Valence: 0.1698\n",
            "Test MAE Arousal: 0.1376, RMSE Arousal: 0.1843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 SEC done\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Function to load and preprocess audio dataset\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values # Adjusted to slice till the end\n",
        "    y = data[[\"valence\", \"arousal\"]].values\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# Define a fully connected neural network for regression\n",
        "class FullyConnectedNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FullyConnectedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "# RMSE Loss Function\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        return torch.sqrt(self.mse(yhat, y))\n",
        "\n",
        "# Function to predict on dev set\n",
        "def predict_on_dev(model, dev_loader):\n",
        "    y_valence_true, y_valence_pred = [], []\n",
        "    y_arousal_true, y_arousal_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dev_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence, labels_arousal = labels[:, 0], labels[:, 1]\n",
        "            outputs_valence, outputs_arousal = outputs[:, 0], outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
        "\n",
        "train_file = \"/content/drive/MyDrive/3sec/SEWA_features_wav2vec_3_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/3sec/SEWA_features_wav2vec_3_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/3sec/SEWA_features_wav2vec_3_seconds_test.csv\"\n",
        "\n",
        "# Load and preprocess datasets\n",
        "X_train, y_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(TensorDataset(X_dev, y_dev), batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Neural Network Hyperparameters\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Model, Loss Function, and Optimizer\n",
        "model = FullyConnectedNN(input_dim, hidden_dim, output_dim)\n",
        "criterion_arousal = RMSELoss()\n",
        "criterion_valence = RMSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Instantiate the scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7, verbose=True)\n",
        "\n",
        "# Initialize early stopping parameters\n",
        "patience = 10\n",
        "min_val_loss = float('inf')\n",
        "counter = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss_arousal = criterion_arousal(outputs[:, 0], labels[:, 0])\n",
        "        loss_valence = criterion_valence(outputs[:, 1], labels[:, 1])\n",
        "        loss = loss_arousal + loss_valence\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    val_mae_valence, val_rmse_valence, val_mae_arousal, val_rmse_arousal = predict_on_dev(model, dev_loader)\n",
        "\n",
        "    # Early stopping checks\n",
        "    val_loss = (val_rmse_valence + val_rmse_arousal) / 2\n",
        "    print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        counter = 0\n",
        "        best_epoch = epoch\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), 'best_model_audio-THREE-SEC.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "print(f\"Training stopped after {best_epoch+1} epochs\")\n",
        "\n",
        "def evaluate_on_test(model, test_loader):\n",
        "    y_valence_true = []\n",
        "    y_valence_pred = []\n",
        "    y_arousal_true = []\n",
        "    y_arousal_pred = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence = labels[:, 0]\n",
        "            labels_arousal = labels[:, 1]\n",
        "            outputs_valence = outputs[:, 0]\n",
        "            outputs_arousal = outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    print(f\"Test MAE Valence: {mae_valence:.4f}, RMSE Valence: {rmse_valence:.4f}\")\n",
        "    print(f\"Test MAE Arousal: {mae_arousal:.4f}, RMSE Arousal: {rmse_arousal:.4f}\")\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model_audio-THREE-SEC.pth'))\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "evaluate_on_test(model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CT2UoB7klur",
        "outputId": "d57da0bd-f4ce-4aae-93f6-147e5b07d37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.1257\n",
            "Epoch 2, Val Loss: 0.1268\n",
            "Epoch 3, Val Loss: 0.1255\n",
            "Epoch 4, Val Loss: 0.1247\n",
            "Epoch 5, Val Loss: 0.1241\n",
            "Epoch 6, Val Loss: 0.1265\n",
            "Epoch 7, Val Loss: 0.1248\n",
            "Epoch 8, Val Loss: 0.1247\n",
            "Epoch 9, Val Loss: 0.1247\n",
            "Epoch 10, Val Loss: 0.1249\n",
            "Epoch 11, Val Loss: 0.1275\n",
            "Epoch 12, Val Loss: 0.1274\n",
            "Epoch 13, Val Loss: 0.1253\n",
            "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 14, Val Loss: 0.1251\n",
            "Epoch 15, Val Loss: 0.1248\n",
            "Early stopping triggered\n",
            "Training stopped after 5 epochs\n",
            "Test MAE Valence: 0.1325, RMSE Valence: 0.1665\n",
            "Test MAE Arousal: 0.1379, RMSE Arousal: 0.1863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 SEC done\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Function to load and preprocess audio dataset\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values # Adjusted to slice till the end\n",
        "    y = data[[\"valence\", \"arousal\"]].values\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# Define a fully connected neural network for regression\n",
        "class FullyConnectedNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FullyConnectedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "# RMSE Loss Function\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        return torch.sqrt(self.mse(yhat, y))\n",
        "\n",
        "# Function to predict on dev set\n",
        "def predict_on_dev(model, dev_loader):\n",
        "    y_valence_true, y_valence_pred = [], []\n",
        "    y_arousal_true, y_arousal_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dev_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence, labels_arousal = labels[:, 0], labels[:, 1]\n",
        "            outputs_valence, outputs_arousal = outputs[:, 0], outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
        "\n",
        "train_file = \"/content/drive/MyDrive/4sec/SEWA_features_wav2vec_4_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/4sec/SEWA_features_wav2vec_4_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/4sec/SEWA_features_wav2vec_4_seconds_test.csv\"\n",
        "\n",
        "# Load and preprocess datasets\n",
        "X_train, y_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(TensorDataset(X_dev, y_dev), batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Neural Network Hyperparameters\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Model, Loss Function, and Optimizer\n",
        "model = FullyConnectedNN(input_dim, hidden_dim, output_dim)\n",
        "criterion_arousal = RMSELoss()\n",
        "criterion_valence = RMSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Instantiate the scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7, verbose=True)\n",
        "\n",
        "# Initialize early stopping parameters\n",
        "patience = 10\n",
        "min_val_loss = float('inf')\n",
        "counter = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss_arousal = criterion_arousal(outputs[:, 0], labels[:, 0])\n",
        "        loss_valence = criterion_valence(outputs[:, 1], labels[:, 1])\n",
        "        loss = loss_arousal + loss_valence\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    val_mae_valence, val_rmse_valence, val_mae_arousal, val_rmse_arousal = predict_on_dev(model, dev_loader)\n",
        "\n",
        "    # Early stopping checks\n",
        "    val_loss = (val_rmse_valence + val_rmse_arousal) / 2\n",
        "    print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        counter = 0\n",
        "        best_epoch = epoch\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), 'best_model_audio-FOUR-SEC.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "print(f\"Training stopped after {best_epoch+1} epochs\")\n",
        "\n",
        "def evaluate_on_test(model, test_loader):\n",
        "    y_valence_true = []\n",
        "    y_valence_pred = []\n",
        "    y_arousal_true = []\n",
        "    y_arousal_pred = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence = labels[:, 0]\n",
        "            labels_arousal = labels[:, 1]\n",
        "            outputs_valence = outputs[:, 0]\n",
        "            outputs_arousal = outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "    mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    print(f\"Test MAE Valence: {mae_valence:.4f}, RMSE Valence: {rmse_valence:.4f}\")\n",
        "    print(f\"Test MAE Arousal: {mae_arousal:.4f}, RMSE Arousal: {rmse_arousal:.4f}\")\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model_audio-FOUR-SEC.pth'))\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "evaluate_on_test(model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w_FbMQnk0cc",
        "outputId": "2dde9267-53f9-4e9a-c27a-520733e8413d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.1285\n",
            "Epoch 2, Val Loss: 0.1259\n",
            "Epoch 3, Val Loss: 0.1262\n",
            "Epoch 4, Val Loss: 0.1256\n",
            "Epoch 5, Val Loss: 0.1264\n",
            "Epoch 6, Val Loss: 0.1257\n",
            "Epoch 7, Val Loss: 0.1275\n",
            "Epoch 8, Val Loss: 0.1249\n",
            "Epoch 9, Val Loss: 0.1266\n",
            "Epoch 10, Val Loss: 0.1258\n",
            "Epoch 11, Val Loss: 0.1260\n",
            "Epoch 12, Val Loss: 0.1260\n",
            "Epoch 13, Val Loss: 0.1270\n",
            "Epoch 14, Val Loss: 0.1250\n",
            "Epoch 15, Val Loss: 0.1242\n",
            "Epoch 16, Val Loss: 0.1260\n",
            "Epoch 17, Val Loss: 0.1245\n",
            "Epoch 18, Val Loss: 0.1244\n",
            "Epoch 19, Val Loss: 0.1259\n",
            "Epoch 20, Val Loss: 0.1249\n",
            "Epoch 21, Val Loss: 0.1250\n",
            "Epoch 22, Val Loss: 0.1256\n",
            "Epoch 23, Val Loss: 0.1286\n",
            "Epoch 00023: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 24, Val Loss: 0.1249\n",
            "Epoch 25, Val Loss: 0.1252\n",
            "Early stopping triggered\n",
            "Training stopped after 15 epochs\n",
            "Test MAE Valence: 0.1338, RMSE Valence: 0.1672\n",
            "Test MAE Arousal: 0.1339, RMSE Arousal: 0.1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVR 1 sec\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
        "    y_arousal = data['arousal'].values\n",
        "    y_valence = data['valence'].values\n",
        "    return X, y_arousal, y_valence\n",
        "\n",
        "# Scale features (function)\n",
        "def scale_features(X_train, X_dev, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_dev_scaled = scaler.transform(X_dev)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    return X_train_scaled, X_dev_scaled, X_test_scaled\n",
        "\n",
        "# SVR Grid Search (function)\n",
        "def svr_grid_search(X_train, y_train, X_dev, y_dev, param_grid):\n",
        "    concat_x_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
        "    concat_y_train_dev = np.concatenate((y_train, y_dev), axis=0)\n",
        "    split_index = [-1 for _ in X_train] + [0 for _ in X_dev]  # PredefinedSplit indices\n",
        "    pds = PredefinedSplit(test_fold=split_index)\n",
        "\n",
        "    svr = SVR()\n",
        "    grid_search = GridSearchCV(svr, param_grid, cv=pds, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(concat_x_train_dev, concat_y_train_dev)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Evaluate Model (function)\n",
        "def evaluate_model(model, X_dev, y_dev, X_test, y_test):\n",
        "    # Dev set\n",
        "    y_dev_pred = model.predict(X_dev)\n",
        "    mse_dev = mean_squared_error(y_dev, y_dev_pred)\n",
        "    rmse_dev = sqrt(mse_dev)\n",
        "    # Test set\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "    rmse_test = sqrt(mse_test)\n",
        "    return mse_dev, rmse_dev, mse_test, rmse_test\n",
        "\n",
        "# Paths to datasets\n",
        "train_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_test.csv\"\n",
        "\n",
        "# Load and preprocess datasets\n",
        "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Scale features\n",
        "X_train_scaled, X_dev_scaled, X_test_scaled = scale_features(X_train, X_dev, X_test)\n",
        "\n",
        "# SVR parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Arousal Model\n",
        "best_svr_arousal = svr_grid_search(X_train_scaled, y_arousal_train, X_dev_scaled, y_arousal_dev, param_grid)\n",
        "mse_arousal_dev, rmse_arousal_dev, mse_arousal_test, rmse_arousal_test = evaluate_model(best_svr_arousal, X_dev_scaled, y_arousal_dev, X_test_scaled, y_arousal_test)\n",
        "\n",
        "# Valence Model\n",
        "best_svr_valence = svr_grid_search(X_train_scaled, y_valence_train, X_dev_scaled, y_valence_dev, param_grid)\n",
        "mse_valence_dev, rmse_valence_dev, mse_valence_test, rmse_valence_test = evaluate_model(best_svr_valence, X_dev_scaled, y_valence_dev, X_test_scaled, y_valence_test)\n",
        "\n",
        "# Results\n",
        "print(\"Arousal - Dev MSE:\", mse_arousal_dev, \"Dev RMSE:\", rmse_arousal_dev, \"Test MSE:\", mse_arousal_test, \"Test RMSE:\", rmse_arousal_test)\n",
        "print(\"Valence - Dev MSE:\", mse_valence_dev, \"Dev RMSE:\", rmse_valence_dev, \"Test MSE:\", mse_valence_test, \"Test RMSE:\", rmse_valence_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "RQqUfEEdlz6s",
        "outputId": "77898c7e-02cf-4f07-9d3f-24a9b0a14b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-fed0b846e6ff>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Arousal Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mbest_svr_arousal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvr_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_arousal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_arousal_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mmse_arousal_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_arousal_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_arousal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_arousal_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_svr_arousal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_arousal_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_arousal_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-fed0b846e6ff>\u001b[0m in \u001b[0;36msvr_grid_search\u001b[0;34m(X_train, y_train, X_dev, y_dev, param_grid)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_x_train_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_y_train_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/svm/_libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm.fit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 sec, decision tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import sqrt\n",
        "\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
        "    y_arousal = data['arousal'].values\n",
        "    y_valence = data['valence'].values\n",
        "    return X, y_arousal, y_valence\n",
        "\n",
        "def scale_features(X):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(X)\n",
        "\n",
        "# Load and preprocess the datasets\n",
        "train_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/1sec/SEWA_features_wav2vec_1_seconds_test.csv\"\n",
        "\n",
        "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Optionally scale features (if not already scaled)\n",
        "X_train_scaled = scale_features(X_train)\n",
        "X_dev_scaled = scale_features(X_dev)\n",
        "X_test_scaled = scale_features(X_test)\n",
        "\n",
        "# Decision Tree Regressor for Arousal\n",
        "regressor_arousal = DecisionTreeRegressor(random_state=42)\n",
        "regressor_arousal.fit(X_train_scaled, y_arousal_train)\n",
        "\n",
        "# Arousal Predictions and Metrics\n",
        "y_arousal_dev_pred = regressor_arousal.predict(X_dev_scaled)\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "rmse_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "y_arousal_test_pred = regressor_arousal.predict(X_test_scaled)\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "rmse_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "# Decision Tree Regressor for Valence\n",
        "regressor_valence = DecisionTreeRegressor(random_state=42)\n",
        "regressor_valence.fit(X_train_scaled, y_valence_train)\n",
        "\n",
        "# Valence Predictions and Metrics\n",
        "y_valence_dev_pred = regressor_valence.predict(X_dev_scaled)\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "rmse_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "y_valence_test_pred = regressor_valence.predict(X_test_scaled)\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "rmse_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "# Results Output\n",
        "print(\"Arousal - Dev RMSE:\", rmse_arousal_dev, \"Test RMSE:\", rmse_arousal_test)\n",
        "print(\"Valence - Dev RMSE:\", rmse_valence_dev, \"Test RMSE:\", rmse_valence_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTd81qWZxHD5",
        "outputId": "abbd78c3-a00b-4655-cf8f-d40753d15a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arousal - Dev RMSE: 0.1973916847658415 Test RMSE: 0.24247219920806407\n",
            "Valence - Dev RMSE: 0.21595636185233033 Test RMSE: 0.23319716413073385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 sec, decision tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import sqrt\n",
        "\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
        "    y_arousal = data['arousal'].values\n",
        "    y_valence = data['valence'].values\n",
        "    return X, y_arousal, y_valence\n",
        "\n",
        "def scale_features(X):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(X)\n",
        "\n",
        "# Load and preprocess the datasets\n",
        "train_file = \"/content/drive/MyDrive/2sec/SEWA_features_wav2vec_2_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/2sec/SEWA_features_wav2vec_2_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/2sec/SEWA_features_wav2vec_2_seconds_test.csv\"\n",
        "\n",
        "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Optionally scale features (if not already scaled)\n",
        "X_train_scaled = scale_features(X_train)\n",
        "X_dev_scaled = scale_features(X_dev)\n",
        "X_test_scaled = scale_features(X_test)\n",
        "\n",
        "# Decision Tree Regressor for Arousal\n",
        "regressor_arousal = DecisionTreeRegressor(random_state=42)\n",
        "regressor_arousal.fit(X_train_scaled, y_arousal_train)\n",
        "\n",
        "# Arousal Predictions and Metrics\n",
        "y_arousal_dev_pred = regressor_arousal.predict(X_dev_scaled)\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "rmse_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "y_arousal_test_pred = regressor_arousal.predict(X_test_scaled)\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "rmse_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "# Decision Tree Regressor for Valence\n",
        "regressor_valence = DecisionTreeRegressor(random_state=42)\n",
        "regressor_valence.fit(X_train_scaled, y_valence_train)\n",
        "\n",
        "# Valence Predictions and Metrics\n",
        "y_valence_dev_pred = regressor_valence.predict(X_dev_scaled)\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "rmse_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "y_valence_test_pred = regressor_valence.predict(X_test_scaled)\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "rmse_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "# Results Output\n",
        "print(\"Arousal - Dev RMSE:\", rmse_arousal_dev, \"Test RMSE:\", rmse_arousal_test)\n",
        "print(\"Valence - Dev RMSE:\", rmse_valence_dev, \"Test RMSE:\", rmse_valence_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_geCvK_0Fms",
        "outputId": "c8754bac-6af7-4937-8762-070baf041b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arousal - Dev RMSE: 0.19844405179331806 Test RMSE: 0.2416438084199608\n",
            "Valence - Dev RMSE: 0.2526523052868014 Test RMSE: 0.2273068760610807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 sec, decision tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import sqrt\n",
        "\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
        "    y_arousal = data['arousal'].values\n",
        "    y_valence = data['valence'].values\n",
        "    return X, y_arousal, y_valence\n",
        "\n",
        "def scale_features(X):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(X)\n",
        "\n",
        "# Load and preprocess the datasets\n",
        "train_file = \"/content/drive/MyDrive/3sec/SEWA_features_wav2vec_3_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/3sec/SEWA_features_wav2vec_3_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/3sec/SEWA_features_wav2vec_3_seconds_test.csv\"\n",
        "\n",
        "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Optionally scale features (if not already scaled)\n",
        "X_train_scaled = scale_features(X_train)\n",
        "X_dev_scaled = scale_features(X_dev)\n",
        "X_test_scaled = scale_features(X_test)\n",
        "\n",
        "# Decision Tree Regressor for Arousal\n",
        "regressor_arousal = DecisionTreeRegressor(random_state=42)\n",
        "regressor_arousal.fit(X_train_scaled, y_arousal_train)\n",
        "\n",
        "# Arousal Predictions and Metrics\n",
        "y_arousal_dev_pred = regressor_arousal.predict(X_dev_scaled)\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "rmse_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "y_arousal_test_pred = regressor_arousal.predict(X_test_scaled)\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "rmse_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "# Decision Tree Regressor for Valence\n",
        "regressor_valence = DecisionTreeRegressor(random_state=42)\n",
        "regressor_valence.fit(X_train_scaled, y_valence_train)\n",
        "\n",
        "# Valence Predictions and Metrics\n",
        "y_valence_dev_pred = regressor_valence.predict(X_dev_scaled)\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "rmse_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "y_valence_test_pred = regressor_valence.predict(X_test_scaled)\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "rmse_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "# Results Output\n",
        "print(\"Arousal - Dev RMSE:\", rmse_arousal_dev, \"Test RMSE:\", rmse_arousal_test)\n",
        "print(\"Valence - Dev RMSE:\", rmse_valence_dev, \"Test RMSE:\", rmse_valence_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf2UjbF30OSP",
        "outputId": "cc272b9d-e839-419a-a3fa-202236e97e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arousal - Dev RMSE: 0.19954608690173675 Test RMSE: 0.229942982178242\n",
            "Valence - Dev RMSE: 0.19275209310988592 Test RMSE: 0.2130777565836836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 sec, decision tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import sqrt\n",
        "\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "    features_start_col = data.columns.get_loc(\"x_0\")\n",
        "    X = data.iloc[:, features_start_col:].values  # Adjusted to slice till the end\n",
        "    y_arousal = data['arousal'].values\n",
        "    y_valence = data['valence'].values\n",
        "    return X, y_arousal, y_valence\n",
        "\n",
        "def scale_features(X):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(X)\n",
        "\n",
        "# Load and preprocess the datasets\n",
        "train_file = \"/content/drive/MyDrive/4sec/SEWA_features_wav2vec_4_seconds_train.csv\"\n",
        "dev_file = \"/content/drive/MyDrive/4sec/SEWA_features_wav2vec_4_seconds_dev.csv\"\n",
        "test_file = \"/content/drive/MyDrive/4sec/SEWA_features_wav2vec_4_seconds_test.csv\"\n",
        "\n",
        "X_train, y_arousal_train, y_valence_train = load_and_preprocess_dataset(train_file)\n",
        "X_dev, y_arousal_dev, y_valence_dev = load_and_preprocess_dataset(dev_file)\n",
        "X_test, y_arousal_test, y_valence_test = load_and_preprocess_dataset(test_file)\n",
        "\n",
        "# Optionally scale features (if not already scaled)\n",
        "X_train_scaled = scale_features(X_train)\n",
        "X_dev_scaled = scale_features(X_dev)\n",
        "X_test_scaled = scale_features(X_test)\n",
        "\n",
        "# Decision Tree Regressor for Arousal\n",
        "regressor_arousal = DecisionTreeRegressor(random_state=42)\n",
        "regressor_arousal.fit(X_train_scaled, y_arousal_train)\n",
        "\n",
        "# Arousal Predictions and Metrics\n",
        "y_arousal_dev_pred = regressor_arousal.predict(X_dev_scaled)\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "rmse_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "y_arousal_test_pred = regressor_arousal.predict(X_test_scaled)\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "rmse_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "# Decision Tree Regressor for Valence\n",
        "regressor_valence = DecisionTreeRegressor(random_state=42)\n",
        "regressor_valence.fit(X_train_scaled, y_valence_train)\n",
        "\n",
        "# Valence Predictions and Metrics\n",
        "y_valence_dev_pred = regressor_valence.predict(X_dev_scaled)\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "rmse_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "y_valence_test_pred = regressor_valence.predict(X_test_scaled)\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "rmse_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "# Results Output\n",
        "print(\"Arousal - Dev RMSE:\", rmse_arousal_dev, \"Test RMSE:\", rmse_arousal_test)\n",
        "print(\"Valence - Dev RMSE:\", rmse_valence_dev, \"Test RMSE:\", rmse_valence_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WErKcgH80QBq",
        "outputId": "c4538b44-cb35-4641-b4dd-b41feb5c142e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arousal - Dev RMSE: 0.17957207692538585 Test RMSE: 0.22671376994901732\n",
            "Valence - Dev RMSE: 0.19899053427001887 Test RMSE: 0.22913537936780798\n"
          ]
        }
      ]
    }
  ]
}
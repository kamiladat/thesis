{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01QxGFruqVhK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class CustomVideoDataset(Dataset):\n",
        "    def __init__(self, df, window_size=10, stride=5):\n",
        "        self.df = df\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_windows)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        window_frames = self.video_windows[idx]\n",
        "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[3:]].values.flatten() for frame in window_frames]\n",
        "        # embeddings shape list:(10, 256)\n",
        "        embeddings_flat = np.array(embeddings)\n",
        "        frames_tensor = torch.tensor(embeddings_flat, dtype=torch.float32)\n",
        "\n",
        "        labels = self.labels_windows[idx]\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "        return frames_tensor, labels_tensor\n",
        "\n",
        "    def prepare_windows(self):\n",
        "        video_frames = {}\n",
        "        labels = {}\n",
        "        for _, row in self.df.iterrows():\n",
        "            video_id = self.extract_video_info(row['path'])\n",
        "            if video_id not in video_frames:\n",
        "                video_frames[video_id] = []\n",
        "                labels[video_id] = []\n",
        "            video_frames[video_id].append(row['path'])\n",
        "            labels[video_id].append((row['arousal'], row['valence']))\n",
        "\n",
        "        video_windows = []\n",
        "        labels_windows = []\n",
        "        for video_id in video_frames:\n",
        "            frames = video_frames[video_id]\n",
        "            label_vals = labels[video_id]\n",
        "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
        "                video_windows.append(frames[i:i + self.window_size])\n",
        "                window_labels = label_vals[i:i + self.window_size]\n",
        "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
        "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
        "                labels_windows.append((avg_arousal, avg_valence))\n",
        "\n",
        "        return video_windows, labels_windows\n",
        "\n",
        "    def extract_video_info(self, file_path):\n",
        "        parts = file_path.split('/')\n",
        "        video_id = parts[-2]\n",
        "        return video_id\n",
        "\n",
        "# Load your dataframes\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/AFEW-VA_radiant_fog_160_train.csv')\n",
        "dev_df = pd.read_csv('/content/drive/MyDrive/AFEW-VA_radiant_fog_160_dev.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/AFEW-VA_radiant_fog_160_test.csv')\n",
        "\n",
        "# Create instances of CustomVideoDataset for train, dev, and test\n",
        "train_dataset = CustomVideoDataset(train_df)\n",
        "dev_dataset = CustomVideoDataset(dev_df)\n",
        "test_dataset = CustomVideoDataset(test_df)\n",
        "\n",
        "# Create DataLoaders for train, dev, and test datasets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "tdorv7jiqch2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_on_dev(model, dev_loader):\n",
        "  y_valence_true = []\n",
        "  y_valence_pred = []\n",
        "  y_arousal_true = []\n",
        "  y_arousal_pred = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dev_loader:\n",
        "          outputs = model(inputs)\n",
        "          labels_valence = labels[:, 0]\n",
        "          labels_arousal = labels[:, 1]\n",
        "          outputs_valence = outputs[:, 0]\n",
        "          outputs_arousal = outputs[:, 1]\n",
        "\n",
        "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "  # Calculate metrics\n",
        "  mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "  rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "  mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "  rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "  return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)"
      ],
      "metadata": {
        "id": "_IQou9FmqhLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "class FullyConnectedNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FullyConnectedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "       # Flatten the last two dimensions\n",
        "       # x = x.view(x.size(0), -1)  # Reshapes input to [batch_size, window_size * embeddings_per_frame]\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)  # Apply tanh activation to the output\n",
        "        return x\n",
        "\n",
        "# Define the window size and calculate the input dimension\n",
        "window_size = 10  # Assuming a window size of 10 frames\n",
        "embeddings_per_frame = 256\n",
        "input_dim = window_size * embeddings_per_frame  # 10 frames * 256 embeddings per frame\n",
        "\n",
        "# Define your model and training hyperparameters\n",
        "hidden_dim = 64\n",
        "output_dim = 2  # Arousal and Valence\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Instantiate the model\n",
        "model = FullyConnectedNN(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Define separate loss functions for arousal and valence\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        return torch.sqrt(self.mse(yhat, y))\n",
        "\n",
        "criterion_arousal = RMSELoss()\n",
        "criterion_valence = RMSELoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define early stopping parameters\n",
        "patience = 10  # Number of epochs to wait for improvement\n",
        "min_val_loss = float('inf')\n",
        "counter = 0  # Counter for epochs without improvement\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "best_mae_arousal = float('inf')\n",
        "best_mae_valence = float('inf')\n",
        "best_rmse_arousal = float('inf')\n",
        "best_rmse_valence = float('inf')\n",
        "stop_training = False\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "       # print(inputs.shape)\n",
        "       # print(\"---------------\")\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Split predicted values into arousal and valence\n",
        "        predicted_arousal = outputs[:, 0]\n",
        "        predicted_valence = outputs[:, 1]\n",
        "\n",
        "        # Split ground truth labels into arousal and valence\n",
        "        labels_arousal = labels[:, 0]\n",
        "        labels_valence = labels[:, 1]\n",
        "\n",
        "        # Calculate separate losses for arousal and valence\n",
        "        loss_arousal = criterion_arousal(predicted_arousal, labels_arousal)\n",
        "        loss_valence = criterion_valence(predicted_valence, labels_valence)\n",
        "        loss = loss_arousal + loss_valence\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Predict on dev data using the trained model\n",
        "    model.eval()\n",
        "    dev_mae_valence, dev_rmse_valence, dev_mae_arousal, dev_rmse_arousal = predict_on_dev(model, dev_loader)\n",
        "    general_rmse_metric = (dev_rmse_valence + dev_rmse_arousal) / 2.\n",
        "\n",
        "    print(f\"Validation RMSE: {general_rmse_metric:.4f}\")\n",
        "\n",
        "    # Check Early stopping criteria\n",
        "    if general_rmse_metric < min_val_loss:  # Check if the validation loss has improved\n",
        "      min_val_loss = general_rmse_metric\n",
        "      counter = 0\n",
        "\n",
        "    # Save the model weights if RMSE is lower than the best value\n",
        "      #if dev_rmse_arousal < best_rmse_arousal and dev_rmse_valence < best_rmse_valence:\n",
        "      best_rmse_arousal = dev_rmse_arousal\n",
        "      best_mae_arousal = dev_mae_arousal\n",
        "      best_rmse_valence = dev_rmse_valence\n",
        "      best_mae_valence = dev_mae_valence\n",
        "      best_epoch = epoch\n",
        "      torch.save(model.state_dict(), 'best_model_SEWA.pth') #should be called AFEW actually\n",
        "    else:\n",
        "        counter += 1\n",
        "    # If the validation loss hasn't improved for 'patience' epochs, set the stop_training variable\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
        "        stop_training = True\n",
        "    if stop_training:\n",
        "        break\n",
        "\n",
        "# Print the last best results and epoch\n",
        "if stop_training:\n",
        "    print(f\"Best RMSE Arousal: {best_rmse_arousal:.4f} at epoch {best_epoch + 1}\")\n",
        "    print(f\"Best MAE Arousal: {best_mae_arousal:.4f} at epoch {best_epoch + 1}\")\n",
        "    print(f\"Best RMSE Valence: {best_rmse_valence:.4f} at epoch {best_epoch + 1}\")\n",
        "    print(f\"Best MAE Valence: {best_mae_valence:.4f} at epoch {best_epoch + 1}\")\n",
        "else:\n",
        "    print(\"Training completed without early stopping\")\n",
        "\n",
        "def evaluate_on_test(model, test_loader):\n",
        "    model.eval()\n",
        "    y_valence_true = []\n",
        "    y_valence_pred = []\n",
        "    y_arousal_true = []\n",
        "    y_arousal_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence = labels[:, 0]\n",
        "            labels_arousal = labels[:, 1]\n",
        "            outputs_valence = outputs[:, 0]\n",
        "            outputs_arousal = outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy().flatten())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy().flatten())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy().flatten())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae_valence_test = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence_test = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal_test = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal_test = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    return mae_valence_test, rmse_valence_test, mae_arousal_test, rmse_arousal_test\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('/content/best_model_AFEW-TESTT.pth')) #AFEW actually\n",
        "model.eval()\n",
        "\n",
        "# Call the evaluate_on_test function\n",
        "mae_valence_test, rmse_valence_test, mae_arousal_test, rmse_arousal_test = evaluate_on_test(model, test_loader)\n",
        "\n",
        "# Print the results for the test dataset\n",
        "print(f\"Test MAE Valence: {mae_valence_test:.4f}, Test RMSE Valence: {rmse_valence_test:.4f}\")\n",
        "print(f\"Test MAE Arousal: {mae_arousal_test:.4f}, Test RMSE Arousal: {rmse_arousal_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "PvpODpZGqjnW",
        "outputId": "bf5bfb02-51a1-4566-a279-6846483a0943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 3.0264\n",
            "Validation RMSE: 3.0303\n",
            "Validation RMSE: 3.0270\n",
            "Validation RMSE: 3.0282\n",
            "Validation RMSE: 3.0289\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f7323a6a1a87>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m        \u001b[0;31m# print(inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1e64c2551a04>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mwindow_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_windows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindow_frames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# embeddings shape list:(10, 256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0membeddings_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1e64c2551a04>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mwindow_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_windows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindow_frames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# embeddings shape list:(10, 256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0membeddings_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_ellipsis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;31m# we may have a nested tuples indexer here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_nested_tuple_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_nested_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_nested_tuple_indexer\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_nested_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#LSTM:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomVideoDataset(Dataset):\n",
        "    def __init__(self, df, window_size=10, stride=5):\n",
        "        self.df = df\n",
        "        self.df['arousal'] = self.df['arousal'] / 10.\n",
        "        self.df['valence'] = self.df['valence'] / 10.\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "        self.video_windows, self.labels_windows = self.prepare_windows()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_windows)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        window_frames = self.video_windows[idx]\n",
        "        embeddings = [self.df.loc[self.df['path'] == frame, self.df.columns[3:]].values for frame in window_frames]\n",
        "        frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n",
        "\n",
        "\n",
        "        labels = self.labels_windows[idx]\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        return frames_tensor, labels_tensor\n",
        "\n",
        "\n",
        "    def prepare_windows(self):\n",
        "        video_frames = {}\n",
        "        labels = {}\n",
        "        for _, row in self.df.iterrows():\n",
        "            video_id = self.extract_video_info(row['path'])\n",
        "            if video_id not in video_frames:\n",
        "                video_frames[video_id] = []\n",
        "                labels[video_id] = []\n",
        "            video_frames[video_id].append(row['path'])\n",
        "            labels[video_id].append((row['arousal'], row['valence']))\n",
        "\n",
        "\n",
        "        video_windows = []\n",
        "        labels_windows = []\n",
        "        for video_id in video_frames:\n",
        "            frames = video_frames[video_id]\n",
        "            label_vals = labels[video_id]\n",
        "            for i in range(0, len(frames) - self.window_size + 1, self.stride):\n",
        "                video_windows.append(frames[i:i + self.window_size])\n",
        "                window_labels = label_vals[i:i + self.window_size]\n",
        "                avg_arousal = sum([label[0] for label in window_labels]) / len(window_labels)\n",
        "                avg_valence = sum([label[1] for label in window_labels]) / len(window_labels)\n",
        "                labels_windows.append((avg_arousal, avg_valence))\n",
        "\n",
        "\n",
        "        return video_windows, labels_windows\n",
        "\n",
        "\n",
        "    def extract_video_info(self, file_path):\n",
        "        parts = file_path.split('/')\n",
        "        video_id = parts[-2]\n",
        "        return video_id\n",
        "\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/AFEW-VA_radiant_fog_160_train.csv')\n",
        "dev_df = pd.read_csv('/content/drive/MyDrive/AFEW-VA_radiant_fog_160_dev.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/AFEW-VA_radiant_fog_160_test.csv')\n",
        "\n",
        "# Hyperparameters\n",
        "window_size = 10\n",
        "input_size = 256  # Number of features (embeddings) per frame\n",
        "hidden_size = 128  # Number of features in hidden state of LSTM\n",
        "output_size = 2  # Output size (arousal and valence)\n",
        "num_layers = 2 # Number of LSTM layers\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = CustomVideoDataset(train_df, window_size)\n",
        "dev_dataset = CustomVideoDataset(dev_df, window_size)\n",
        "test_dataset = CustomVideoDataset(test_df, window_size)\n",
        "\n",
        "batch_size = 64 #before:32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# LSTM Network\n",
        "class LSTMNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, bidirectional=True):\n",
        "        super(LSTMNetwork, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional #bidirectional lstm\n",
        "        #self.dropout = nn.Dropout(0.5) #add dropout before fully con.layer if overfitting\n",
        "\n",
        "\n",
        "        # LSTM Layer\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional) # GRU instead of LSTM\n",
        "\n",
        "\n",
        "        # Fully connected layer\n",
        "        # Multiply hidden_size by 2 if bidirectional\n",
        "        fc_input_size = hidden_size * 2 if bidirectional else hidden_size\n",
        "        self.fc = nn.Linear(fc_input_size, output_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "        #self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        #out = self.dropout(out)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.tanh(out)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTMNetwork(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#adding learning rate scheduler to dynamically adjust the LR\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n",
        "\n",
        "# Training loop\n",
        "early_stopping_patience = 5\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_train_loss = total_train_loss / num_batches\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0\n",
        "        for inputs, labels in dev_loader:\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "        avg_val_loss = total_val_loss / len(dev_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    #Early stopping\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        # Save the model if desired\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            y_true.append(labels.numpy())\n",
        "            y_pred.append(outputs.numpy())\n",
        "\n",
        "\n",
        "    y_true = np.concatenate(y_true, axis=0)\n",
        "    y_pred = np.concatenate(y_pred, axis=0)\n",
        "\n",
        "\n",
        "    mae_valence = mean_absolute_error(y_true[:, 0], y_pred[:, 0])\n",
        "    rmse_valence = sqrt(mean_squared_error(y_true[:, 0], y_pred[:, 0]))\n",
        "    mae_arousal = mean_absolute_error(y_true[:, 1], y_pred[:, 1])\n",
        "    rmse_arousal = sqrt(mean_squared_error(y_true[:, 1], y_pred[:, 1]))\n",
        "\n",
        "\n",
        "    return mae_valence, rmse_valence, mae_arousal, rmse_arousal\n",
        "\n",
        "\n",
        "# Evaluate the model on test data\n",
        "mae_valence, rmse_valence, mae_arousal, rmse_arousal = evaluate_model(model, test_loader)\n",
        "\n",
        "\n",
        "print(f\"Test MAE Valence: {mae_valence:.4f}, Test RMSE Valence: {rmse_valence:.4f}\")\n",
        "print(f\"Test MAE Arousal: {mae_arousal:.4f}, Test RMSE Arousal: {rmse_arousal:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyafkBEK6KUg",
        "outputId": "b738bea7-6bda-40e9-d7fb-38714616d4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ebb8559ac786>:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  frames_tensor = torch.tensor(embeddings, dtype=torch.float32).squeeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 6.7890\n",
            "Epoch 1/10, Validation Loss: 8.9403\n",
            "Epoch 2/10, Training Loss: 6.3134\n",
            "Epoch 2/10, Validation Loss: 8.9619\n",
            "Epoch 00004: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Epoch 3/10, Training Loss: 6.2975\n",
            "Epoch 3/10, Validation Loss: 8.9598\n",
            "Epoch 4/10, Training Loss: 6.2606\n",
            "Epoch 4/10, Validation Loss: 8.9346\n",
            "Epoch 5/10, Training Loss: 6.2737\n",
            "Epoch 5/10, Validation Loss: 8.9331\n",
            "Epoch 6/10, Training Loss: 6.2445\n",
            "Epoch 6/10, Validation Loss: 8.9400\n",
            "Epoch 00012: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Epoch 7/10, Training Loss: 6.2097\n",
            "Epoch 7/10, Validation Loss: 8.9432\n",
            "Epoch 8/10, Training Loss: 6.2041\n",
            "Epoch 8/10, Validation Loss: 8.9460\n",
            "Epoch 00015: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Epoch 9/10, Training Loss: 6.2112\n",
            "Epoch 9/10, Validation Loss: 8.9352\n",
            "Epoch 00018: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Epoch 10/10, Training Loss: 6.2379\n",
            "Epoch 10/10, Validation Loss: 8.9375\n",
            "Early stopping triggered\n",
            "Test MAE Valence: 2.2378, Test RMSE Valence: 2.9296\n",
            "Test MAE Arousal: 1.9904, Test RMSE Arousal: 2.7318\n"
          ]
        }
      ]
    }
  ]
}
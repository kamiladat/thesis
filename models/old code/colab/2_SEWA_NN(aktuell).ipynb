{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8ZVTBywYl8Q",
        "outputId": "7d4f0e82-1a15-4558-cf1c-ad600e1e4072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_dev(model, dev_loader):\n",
        "  y_valence_true = []\n",
        "  y_valence_pred = []\n",
        "  y_arousal_true = []\n",
        "  y_arousal_pred = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dev_loader:\n",
        "          outputs = model(inputs)\n",
        "          labels_valence = labels[:, 0]\n",
        "          labels_arousal = labels[:, 1]\n",
        "          outputs_valence = outputs[:, 0]\n",
        "          outputs_arousal = outputs[:, 1]\n",
        "\n",
        "          y_valence_true.extend(labels_valence.cpu().numpy())\n",
        "          y_valence_pred.extend(outputs_valence.cpu().numpy())\n",
        "          y_arousal_true.extend(labels_arousal.cpu().numpy())\n",
        "          y_arousal_pred.extend(outputs_arousal.cpu().numpy())\n",
        "\n",
        "  # Calculate metrics\n",
        "  mae_valence = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "  rmse_valence = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "  mae_arousal = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "  rmse_arousal = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "  return (mae_valence, rmse_valence, mae_arousal, rmse_arousal)"
      ],
      "metadata": {
        "id": "Oodc9v7bYyN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define a function to load and preprocess a dataset\n",
        "def load_and_preprocess_dataset(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "\n",
        "    # Extract features and labels\n",
        "    X = data.loc[:, 'emb_0':].values\n",
        "    y = data[[\"valence\", \"arousal\"]].values  # Use valence and arousal as labels\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# Load and preprocess each dataset\n",
        "X_train_tensor, y_train_tensor = load_and_preprocess_dataset(\"/content/drive/MyDrive/SEWA_radiant_fog_160_train.csv\")\n",
        "X_dev_tensor, y_dev_tensor = load_and_preprocess_dataset(\"/content/drive/MyDrive/SEWA_radiant_fog_160_dev.csv\")\n",
        "X_test_tensor, y_test_tensor = load_and_preprocess_dataset(\"/content/drive/MyDrive/SEWA_radiant_fog_160_test.csv\")\n",
        "\n",
        "# Create DataLoaders for each dataset\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "dev_dataset = TensorDataset(X_dev_tensor, y_dev_tensor)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define your fully connected neural network for regression with tanh activation\n",
        "class FullyConnectedNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FullyConnectedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()  # Apply tanh activation to the output\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)  # Apply tanh activation to the output\n",
        "        return x\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Instantiate the model\n",
        "model = FullyConnectedNN(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Define separate loss functions for arousal and valence\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        return torch.sqrt(self.mse(yhat, y))\n",
        "\n",
        "criterion_arousal = RMSELoss()\n",
        "criterion_valence = RMSELoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define early stopping parameters\n",
        "patience = 10  # Number of epochs to wait for improvement\n",
        "min_val_loss = float('inf')\n",
        "counter = 0  # Counter for epochs without improvement\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "best_mae_arousal = float('inf')\n",
        "best_mae_valence = float('inf')\n",
        "best_rmse_arousal = float('inf')\n",
        "best_rmse_valence = float('inf')\n",
        "stop_training = False\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Split predicted values into arousal and valence\n",
        "        predicted_arousal = outputs[:, 0]\n",
        "        predicted_valence = outputs[:, 1]\n",
        "\n",
        "        # Split ground truth labels into arousal and valence\n",
        "        labels_arousal = labels[:, 0]\n",
        "        labels_valence = labels[:, 1]\n",
        "\n",
        "        # Calculate separate losses for arousal and valence\n",
        "        loss_arousal = criterion_arousal(predicted_arousal, labels_arousal)\n",
        "        loss_valence = criterion_valence(predicted_valence, labels_valence)\n",
        "        loss = loss_arousal + loss_valence\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Predict on dev data using the trained model\n",
        "    model.eval()\n",
        "    dev_mae_valence, dev_rmse_valence, dev_mae_arousal, dev_rmse_arousal = predict_on_dev(model, dev_loader)\n",
        "    general_rmse_metric = (dev_rmse_valence + dev_rmse_arousal) / 2.\n",
        "\n",
        "    print(f\"Validation RMSE: {general_rmse_metric:.4f}\")\n",
        "\n",
        "    # Check Early stopping criteria\n",
        "    if general_rmse_metric < min_val_loss:  # Check if the validation loss has improved\n",
        "      min_val_loss = general_rmse_metric\n",
        "      counter = 0\n",
        "\n",
        "    # Save the model weights if RMSE is lower than the best value\n",
        "      #if dev_rmse_arousal < best_rmse_arousal and dev_rmse_valence < best_rmse_valence:\n",
        "      best_rmse_arousal = dev_rmse_arousal\n",
        "      best_mae_arousal = dev_mae_arousal\n",
        "      best_rmse_valence = dev_rmse_valence\n",
        "      best_mae_valence = dev_mae_valence\n",
        "      best_epoch = epoch\n",
        "      torch.save(model.state_dict(), 'best_model_SEWA.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "    # If the validation loss hasn't improved for 'patience' epochs, set the stop_training variable\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
        "        stop_training = True\n",
        "    if stop_training:\n",
        "        break\n",
        "\n",
        "# Print the last best results and epoch\n",
        "if stop_training:\n",
        "    print(f\"Best RMSE Arousal: {best_rmse_arousal:.4f} at epoch {best_epoch + 1}\")\n",
        "    print(f\"Best MAE Arousal: {best_mae_arousal:.4f} at epoch {best_epoch + 1}\")\n",
        "    print(f\"Best RMSE Valence: {best_rmse_valence:.4f} at epoch {best_epoch + 1}\")\n",
        "    print(f\"Best MAE Valence: {best_mae_valence:.4f} at epoch {best_epoch + 1}\")\n",
        "else:\n",
        "    print(\"Training completed without early stopping\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QygRxfL_Y_R-",
        "outputId": "a612fc9f-a6a3-43a9-c40b-28ccdd573dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 0.0889\n",
            "Validation RMSE: 0.0887\n",
            "Validation RMSE: 0.0917\n",
            "Validation RMSE: 0.0892\n",
            "Validation RMSE: 0.0905\n",
            "Validation RMSE: 0.0897\n",
            "Validation RMSE: 0.0899\n",
            "Validation RMSE: 0.0903\n",
            "Validation RMSE: 0.0910\n",
            "Validation RMSE: 0.0940\n",
            "Validation RMSE: 0.0911\n",
            "Validation RMSE: 0.0932\n",
            "Early stopping at epoch 12 due to no improvement in validation loss.\n",
            "Best RMSE Arousal: 0.0804 at epoch 2\n",
            "Best MAE Arousal: 0.0594 at epoch 2\n",
            "Best RMSE Valence: 0.0971 at epoch 2\n",
            "Best MAE Valence: 0.0685 at epoch 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_on_test(model, test_loader):\n",
        "    model.eval()\n",
        "    y_valence_true = []\n",
        "    y_valence_pred = []\n",
        "    y_arousal_true = []\n",
        "    y_arousal_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            labels_valence = labels[:, 0]\n",
        "            labels_arousal = labels[:, 1]\n",
        "            outputs_valence = outputs[:, 0]\n",
        "            outputs_arousal = outputs[:, 1]\n",
        "\n",
        "            y_valence_true.extend(labels_valence.cpu().numpy().flatten())\n",
        "            y_valence_pred.extend(outputs_valence.cpu().numpy().flatten())\n",
        "            y_arousal_true.extend(labels_arousal.cpu().numpy().flatten())\n",
        "            y_arousal_pred.extend(outputs_arousal.cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae_valence_test = mean_absolute_error(y_valence_true, y_valence_pred)\n",
        "    rmse_valence_test = sqrt(mean_squared_error(y_valence_true, y_valence_pred))\n",
        "    mae_arousal_test = mean_absolute_error(y_arousal_true, y_arousal_pred)\n",
        "    rmse_arousal_test = sqrt(mean_squared_error(y_arousal_true, y_arousal_pred))\n",
        "\n",
        "    return mae_valence_test, rmse_valence_test, mae_arousal_test, rmse_arousal_test"
      ],
      "metadata": {
        "id": "K6NC3-6pZn4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load('/content/best_model_SEWA.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Call the evaluate_on_test function\n",
        "mae_valence_test, rmse_valence_test, mae_arousal_test, rmse_arousal_test = evaluate_on_test(model, test_loader)\n",
        "\n",
        "# Print the results for the test dataset\n",
        "print(f\"Test MAE Valence: {mae_valence_test:.4f}, Test RMSE Valence: {rmse_valence_test:.4f}\")\n",
        "print(f\"Test MAE Arousal: {mae_arousal_test:.4f}, Test RMSE Arousal: {rmse_arousal_test:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn-CcL7tZqmp",
        "outputId": "7274d841-5dde-45ab-dabf-847f69dfd4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE Valence: 0.0928, Test RMSE Valence: 0.1178\n",
            "Test MAE Arousal: 0.0878, Test RMSE Arousal: 0.1124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Only arousal\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "from math import sqrt\n",
        "\n",
        "# Load the training dataset\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_train.csv\")\n",
        "\n",
        "# Load the dev dataset\n",
        "dev_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_dev.csv\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_test.csv\")\n",
        "\n",
        "# Extract features (X) and target (y) for arousal in the training data\n",
        "X_train = train_data.iloc[:, 5:].values  # Features start from column index 5\n",
        "y_arousal_train = train_data[\"arousal\"].values\n",
        "\n",
        "# Extract features (X) and target (y) for arousal in the dev data\n",
        "X_dev = dev_data.iloc[:, 5:].values\n",
        "y_arousal_dev = dev_data[\"arousal\"].values\n",
        "\n",
        "# Extract features (X) and target (y) for arousal in the test data\n",
        "X_test = test_data.iloc[:, 5:].values\n",
        "y_arousal_test = test_data[\"arousal\"].values\n",
        "\n",
        "\n",
        "# Create a parameter grid for SVR\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Concatenate train and dev\n",
        "concat_x_train_dev_arousal = np.concatenate((X_train, X_dev), axis=0)\n",
        "concat_y_arousal_train_dev = np.concatenate((y_arousal_train, y_arousal_dev), axis=0)\n",
        "\n",
        "# Generate indices for training and development parts\n",
        "split_index_arousal = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_dev.shape[0])]\n",
        "\n",
        "# Create PredefinedSplit\n",
        "pds_arousal = PredefinedSplit(test_fold=split_index_arousal)\n",
        "\n",
        "# Use PredefinedSplit in GridSearchCV for Arousal\n",
        "svr_arousal = SVR()\n",
        "grid_search_arousal = GridSearchCV(svr_arousal, param_grid, cv=pds_arousal, scoring='neg_mean_squared_error')\n",
        "grid_search_arousal.fit(concat_x_train_dev_arousal, concat_y_arousal_train_dev)\n",
        "\n",
        "# Get the best estimators\n",
        "best_svr_arousal = grid_search_arousal.best_estimator_\n",
        "\n",
        "# Predict on the dev data for arousal\n",
        "y_arousal_dev_pred = best_svr_arousal.predict(X_dev)\n",
        "\n",
        "# Calculate regression metrics for arousal on the dev data\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "r2_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "print(\"Results for Arousal on Dev Data:\")\n",
        "print(\"Arousal - Mean Squared Error:\", mse_arousal_dev)\n",
        "print(\"Arousal - R-squared:\", r2_arousal_dev)\n",
        "\n",
        "# Predict on the test data for arousal\n",
        "y_arousal_test_pred = best_svr_arousal.predict(X_test)\n",
        "\n",
        "# Calculate regression metrics for arousal on the test data\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "r2_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "print(\"Results for Arousal on Test Data:\")\n",
        "print(\"Arousal - Mean Squared Error:\", mse_arousal_test)\n",
        "print(\"Arousal - R-squared:\", r2_arousal_test)"
      ],
      "metadata": {
        "id": "gDUeWiJAbA_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Only valence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "from math import sqrt\n",
        "\n",
        "# Load the training dataset\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_train.csv\")\n",
        "\n",
        "# Load the dev dataset\n",
        "dev_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_dev.csv\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_test.csv\")\n",
        "\n",
        "# Extract features (X) and target (y) for valence in the training data\n",
        "X_train = train_data.iloc[:, 5:].values  # Features start from column index 4\n",
        "y_valence_train = train_data[\"valence\"].values\n",
        "\n",
        "# Extract features (X) and target (y) for valence in the dev data\n",
        "X_dev = dev_data.iloc[:, 5:].values\n",
        "y_valence_dev = dev_data[\"valence\"].values\n",
        "\n",
        "# Extract features (X) and target (y) for valence in the test data\n",
        "X_test = test_data.iloc[:, 5:].values\n",
        "y_valence_test = test_data[\"valence\"].values\n",
        "\n",
        "# Create a parameter grid for SVR\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Concatenate train and dev\n",
        "concat_x_train_dev_valence = np.concatenate((X_train, X_dev), axis=0)\n",
        "concat_y_valence_train_dev = np.concatenate((y_valence_train, y_valence_dev), axis=0)\n",
        "\n",
        "# Generate indices for training and development parts\n",
        "split_index_valence = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_dev.shape[0])]\n",
        "\n",
        "# Create PredefinedSplit\n",
        "pds_valence = PredefinedSplit(test_fold=split_index_valence)\n",
        "\n",
        "# Use PredefinedSplit in GridSearchCV for Valence\n",
        "svr_valence = SVR()\n",
        "grid_search_valence = GridSearchCV(svr_valence, param_grid, cv=pds_valence, scoring='neg_mean_squared_error')\n",
        "grid_search_valence.fit(concat_x_train_dev_valence, concat_y_valence_train_dev)\n",
        "\n",
        "# Get the best estimators\n",
        "best_svr_valence = grid_search_valence.best_estimator_\n",
        "\n",
        "# Predict on the dev data for valence\n",
        "y_valence_dev_pred = best_svr_valence.predict(X_dev)\n",
        "\n",
        "# Calculate regression metrics for valence on the dev data\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "r2_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "print(\"Results for Valence on Dev Data:\")\n",
        "print(\"Valence - Mean Squared Error:\", mse_valence_dev)\n",
        "print(\"Valence - R-squared:\", r2_valence_dev)\n",
        "\n",
        "# Predict on the test data for valence\n",
        "y_valence_test_pred = best_svr_valence.predict(X_test)\n",
        "\n",
        "# Calculate regression metrics for valence on the test data\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "r2_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "print(\"Results for Valence on Test Data:\")\n",
        "print(\"Valence - Mean Squared Error:\", mse_valence_test)\n",
        "print(\"Valence - R-squared:\", r2_valence_test)"
      ],
      "metadata": {
        "id": "U6-UP_svbE-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from numpy import sqrt\n",
        "\n",
        "# Load the training dataset\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_train.csv\")\n",
        "\n",
        "# Load the dev dataset\n",
        "dev_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_dev.csv\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_test.csv\")\n",
        "\n",
        "# Extract features (X) and target (y) for arousal and valence in the training data\n",
        "X_train = train_data.iloc[:, 4:].values  # Features start from column index 4\n",
        "y_arousal_train = train_data[\"arousal\"].values/10.\n",
        "y_valence_train = train_data[\"valence\"].values/10.\n",
        "\n",
        "# Extract features (X) and target (y) for arousal and valence in the dev data\n",
        "X_dev = dev_data.iloc[:, 4:].values\n",
        "y_arousal_dev = dev_data[\"arousal\"].values/10.\n",
        "y_valence_dev = dev_data[\"valence\"].values/10.\n",
        "\n",
        "# Extract features (X) and target (y) for arousal and valence in the test data\n",
        "X_test = test_data.iloc[:, 4:].values\n",
        "y_arousal_test = test_data[\"arousal\"].values/10.\n",
        "y_valence_test = test_data[\"valence\"].values/10.\n",
        "\n",
        "# Create a Bayesian Ridge regressor for arousal and train it on the training data\n",
        "regressor_arousal = BayesianRidge()\n",
        "regressor_arousal.fit(X_train, y_arousal_train)\n",
        "\n",
        "# Predict on the dev data for arousal\n",
        "y_arousal_dev_pred = regressor_arousal.predict(X_dev)\n",
        "\n",
        "# Calculate regression metrics for arousal on the dev data\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "r2_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "print(\"Results for Arousal on Dev Data:\")\n",
        "print(\"Arousal - Mean Squared Error:\", mse_arousal_dev)\n",
        "print(\"Arousal - R-squared:\", r2_arousal_dev)\n",
        "\n",
        "# Predict on the test data for arousal\n",
        "y_arousal_test_pred = regressor_arousal.predict(X_test)\n",
        "\n",
        "# Calculate regression metrics for arousal on the test data\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "r2_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "print(\"Results for Arousal on Test Data:\")\n",
        "print(\"Arousal - Mean Squared Error:\", mse_arousal_test)\n",
        "print(\"Arousal - R-squared:\", r2_arousal_test)\n",
        "\n",
        "# Create a Bayesian Ridge regressor for valence and train it on the training data\n",
        "regressor_valence = BayesianRidge()\n",
        "regressor_valence.fit(X_train, y_valence_train)\n",
        "\n",
        "# Predict on the dev data for valence\n",
        "y_valence_dev_pred = regressor_valence.predict(X_dev)\n",
        "\n",
        "# Calculate regression metrics for valence on the dev data\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "r2_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "print(\"Results for Valence on Dev Data:\")\n",
        "print(\"Valence - Mean Squared Error:\", mse_valence_dev)\n",
        "print(\"Valence - R-squared:\", r2_valence_dev)\n",
        "\n",
        "# Predict on the test data for valence\n",
        "y_valence_test_pred = regressor_valence.predict(X_test)\n",
        "\n",
        "# Calculate regression metrics for valence on the test data\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "r2_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "print(\"Results for Valence on Test Data:\")\n",
        "print(\"Valence - Mean Squared Error:\", mse_valence_test)\n",
        "print(\"Valence - R-squared:\", r2_valence_test)\n",
        "#Bayessian Ridge FINAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_94eMegDokZ",
        "outputId": "b5890d59-6fef-4b5a-a6d2-9212eb9ca0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Arousal on Dev Data:\n",
            "Arousal - Mean Squared Error: 6.660242806984134e-05\n",
            "Arousal - R-squared: 0.008161031066589646\n",
            "Results for Arousal on Test Data:\n",
            "Arousal - Mean Squared Error: 0.00011932621003503158\n",
            "Arousal - R-squared: 0.010923653694393264\n",
            "Results for Valence on Dev Data:\n",
            "Valence - Mean Squared Error: 0.00010318093754865871\n",
            "Valence - R-squared: 0.01015780180691958\n",
            "Results for Valence on Test Data:\n",
            "Valence - Mean Squared Error: 0.00015333849996393916\n",
            "Valence - R-squared: 0.0123829923671114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from numpy import sqrt\n",
        "\n",
        "# Load the training dataset\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_train.csv\")\n",
        "\n",
        "# Load the dev dataset\n",
        "dev_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_dev.csv\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/SEWA_radiant_fog_160_test.csv\")\n",
        "\n",
        "# Extract features (X) and target (y) for arousal and valence in the training data\n",
        "X_train = train_data.iloc[:, 4:].values  # Features start from column index 4\n",
        "y_arousal_train = train_data[\"arousal\"].values/10.\n",
        "y_valence_train = train_data[\"valence\"].values/10.\n",
        "\n",
        "# Extract features (X) and target (y) for arousal and valence in the dev data\n",
        "X_dev = dev_data.iloc[:, 4:].values\n",
        "y_arousal_dev = dev_data[\"arousal\"].values/10.\n",
        "y_valence_dev = dev_data[\"valence\"].values/10.\n",
        "\n",
        "# Extract features (X) and target (y) for arousal and valence in the test data\n",
        "X_test = test_data.iloc[:, 4:].values\n",
        "y_arousal_test = test_data[\"arousal\"].values/10.\n",
        "y_valence_test = test_data[\"valence\"].values/10.\n",
        "\n",
        "# Create a decision tree regressor for arousal and train it on the training data\n",
        "regressor_arousal = DecisionTreeRegressor(random_state=42)\n",
        "regressor_arousal.fit(X_train, y_arousal_train)\n",
        "\n",
        "# Predict on the dev data for arousal\n",
        "y_arousal_dev_pred = regressor_arousal.predict(X_dev)\n",
        "\n",
        "# Calculate regression metrics for arousal on the dev data\n",
        "mse_arousal_dev = mean_squared_error(y_arousal_dev, y_arousal_dev_pred)\n",
        "r2_arousal_dev = sqrt(mse_arousal_dev)\n",
        "\n",
        "print(\"Results for Arousal on Dev Data:\")\n",
        "print(\"Arousal - Mean Squared Error:\", mse_arousal_dev)\n",
        "print(\"Arousal - R-squared:\", r2_arousal_dev)\n",
        "\n",
        "# Predict on the test data for arousal\n",
        "y_arousal_test_pred = regressor_arousal.predict(X_test)\n",
        "\n",
        "# Calculate regression metrics for arousal on the test data\n",
        "mse_arousal_test = mean_squared_error(y_arousal_test, y_arousal_test_pred)\n",
        "r2_arousal_test = sqrt(mse_arousal_test)\n",
        "\n",
        "print(\"Results for Arousal on Test Data:\")\n",
        "print(\"Arousal - Mean Squared Error:\", mse_arousal_test)\n",
        "print(\"Arousal - R-squared:\", r2_arousal_test)\n",
        "\n",
        "# Create a decision tree regressor for valence and train it on the training data\n",
        "regressor_valence = DecisionTreeRegressor(random_state=42)\n",
        "regressor_valence.fit(X_train, y_valence_train)\n",
        "\n",
        "# Predict on the dev data for valence\n",
        "y_valence_dev_pred = regressor_valence.predict(X_dev)\n",
        "\n",
        "# Calculate regression metrics for valence on the dev data\n",
        "mse_valence_dev = mean_squared_error(y_valence_dev, y_valence_dev_pred)\n",
        "r2_valence_dev = sqrt(mse_valence_dev)\n",
        "\n",
        "print(\"Results for Valence on Dev Data:\")\n",
        "print(\"Valence - Mean Squared Error:\", mse_valence_dev)\n",
        "print(\"Valence - R-squared:\", r2_valence_dev)\n",
        "\n",
        "# Predict on the test data for valence\n",
        "y_valence_test_pred = regressor_valence.predict(X_test)\n",
        "\n",
        "# Calculate regression metrics for valence on the test data\n",
        "mse_valence_test = mean_squared_error(y_valence_test, y_valence_test_pred)\n",
        "r2_valence_test = sqrt(mse_valence_test)\n",
        "\n",
        "print(\"Results for Valence on Test Data:\")\n",
        "print(\"Valence - Mean Squared Error:\", mse_valence_test)\n",
        "print(\"Valence - R-squared:\", r2_valence_test)\n",
        "#DECISION TREE FINAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2jpgyoDFrQM",
        "outputId": "5b66e7c3-0454-4efe-8f4f-51d592eeed62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Arousal on Dev Data:\n",
            "Arousal - Mean Squared Error: 0.00015287751578634253\n",
            "Arousal - R-squared: 0.012364364754662592\n",
            "Results for Arousal on Test Data:\n",
            "Arousal - Mean Squared Error: 0.0002758195099356183\n",
            "Arousal - R-squared: 0.016607814724870287\n",
            "Results for Valence on Dev Data:\n",
            "Valence - Mean Squared Error: 0.00019602042254036995\n",
            "Valence - R-squared: 0.01400072935744313\n",
            "Results for Valence on Test Data:\n",
            "Valence - Mean Squared Error: 0.00030639358706689403\n",
            "Valence - R-squared: 0.017504102006869533\n"
          ]
        }
      ]
    }
  ]
}